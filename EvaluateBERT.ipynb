{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/alexpod1000/SQuAD-QA/blob/main/ModelTrainExperimentalCode_BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "oTkVfFrJ-pzG"
   },
   "outputs": [],
   "source": [
    "#%%bash\n",
    "#[[ ! -e /colabtools ]] && exit  # Continue only if running on Google Colab\n",
    "\n",
    "# Clone repository\n",
    "# https://sysadmins.co.za/clone-a-private-github-repo-with-personal-access-token/\n",
    "# For cloning the main branch:\n",
    "#!git clone https://fb5b65b126107273e595ce8b6c9d2d533103c6e2:x-oauth-basic@github.com/alexpod1000/SQuAD-QA.git\n",
    "# For cloning the \"evaluation-features\" branch\n",
    "#!git clone --branch evaluation-features https://fb5b65b126107273e595ce8b6c9d2d533103c6e2:x-oauth-basic@github.com/alexpod1000/SQuAD-QA.git\n",
    "# Change current working directory to match project\n",
    "#%cd SQuAD-QA/\n",
    "#!pwd\n",
    "\n",
    "#!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "rsBVuJu6_5qN"
   },
   "outputs": [],
   "source": [
    "# External imports\n",
    "import copy\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import torch\n",
    "import json\n",
    "\n",
    "from functools import partial\n",
    "from nltk.tokenize import TreebankWordTokenizer, SpaceTokenizer\n",
    "from transformers import AutoTokenizer\n",
    "from typing import Tuple, List, Dict, Any, Union\n",
    "\n",
    "# Project imports\n",
    "from data_loading.utils import bert_padder_collate_fn_eval\n",
    "from data_loading.qa_dataset import CustomQADatasetBERT_eval\n",
    "from squad_data.parser import SquadFileParser\n",
    "from squad_data.utils import build_mappers_and_dataframe_bert_eval\n",
    "from evaluation.evaluate import evaluate_predictions\n",
    "from evaluation.utils import build_evaluation_dict_bert\n",
    "from utils import split_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters dictionary\n",
    "\n",
    "def prepare_input_distilbert(inputs, device):\n",
    "    model_input = {}\n",
    "    model_input[\"input_ids\"] = inputs[\"input_ids\"].to(device)\n",
    "    model_input[\"attention_mask\"] = inputs[\"attention_mask\"].to(device)\n",
    "    return model_input\n",
    "\n",
    "def prepare_input_albert(inputs, device):\n",
    "    # for now we'll just copy distilbert since it works\n",
    "    model_input = {}\n",
    "    model_input[\"input_ids\"] = inputs[\"input_ids\"].to(device)\n",
    "    model_input[\"attention_mask\"] = inputs[\"attention_mask\"].to(device)\n",
    "    return model_input\n",
    "\n",
    "possible_models_dict = {\n",
    "    \"distilbert\" : {\n",
    "        \"model_url\" : \"distilbert-base-uncased\",\n",
    "        \"tokenizer_url\": \"distilbert-base-uncased\",\n",
    "        \"tokenizer_max_length\": 384,\n",
    "        \"prepare_model_input_fn\": prepare_input_distilbert,\n",
    "        \"train_params\": {\n",
    "            \"epochs\": 2,\n",
    "            \"initial_lr\": 0.00003,\n",
    "            \"batch_size_train\": 32,\n",
    "            \"batch_size_val\": 32,\n",
    "            \"batch_size_test\": 32,\n",
    "            \"weight_decay\": 0.01,\n",
    "            \"dropout_rate\": 0.1\n",
    "        }\n",
    "    },\n",
    "    \"albert\": {\n",
    "        \"model_url\": \"albert-base-v2\",\n",
    "        \"tokenizer_url\": \"albert-base-v2\",\n",
    "        \"tokenizer_max_length\": 384,\n",
    "        \"prepare_model_input_fn\": prepare_input_albert,\n",
    "        \"train_params\": {\n",
    "            \"epochs\": 2,\n",
    "            \"initial_lr\": 0.00003,\n",
    "            \"batch_size_train\": 8,\n",
    "            \"batch_size_val\": 8,\n",
    "            \"batch_size_test\": 8,\n",
    "            \"weight_decay\": 0.01,\n",
    "            \"dropout_rate\": 0.1\n",
    "        }\n",
    "    },\n",
    "    \"distilroberta\": {\n",
    "        \"model_url\": \"distilroberta-base\",\n",
    "        \"tokenizer_url\": \"distilroberta-base\",\n",
    "        \"tokenizer_max_length\": 384,\n",
    "        \"prepare_model_input_fn\": prepare_input_albert,\n",
    "        \"train_params\": {\n",
    "            \"epochs\": 2,\n",
    "            \"initial_lr\": 0.00003,\n",
    "            \"batch_size_train\": 8,\n",
    "            \"batch_size_val\": 8,\n",
    "            \"batch_size_test\": 8,\n",
    "            \"weight_decay\": 0.01,\n",
    "            \"dropout_rate\": 0.1\n",
    "        }\n",
    "    },\n",
    "    \"bert\": {\n",
    "        \"model_url\": \"bert-base-uncased\",\n",
    "        \"tokenizer_url\": \"bert-base-uncased\",\n",
    "        \"tokenizer_max_length\": 384,\n",
    "        \"prepare_model_input_fn\": prepare_input_albert,\n",
    "        \"train_params\": {\n",
    "            \"epochs\": 2,\n",
    "            \"initial_lr\": 0.00003,\n",
    "            \"batch_size_train\": 8,\n",
    "            \"batch_size_val\": 8,\n",
    "            \"batch_size_test\": 8,\n",
    "            \"weight_decay\": 0.01,\n",
    "            \"dropout_rate\": 0.1\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "#current_selected_experiment = \"distilbert\"\n",
    "#current_selected_experiment = \"bert\"\n",
    "#current_selected_experiment = \"albert\"\n",
    "current_selected_experiment = \"distilroberta\"\n",
    "params_dict = possible_models_dict[current_selected_experiment]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Rh4dSW-9tYm"
   },
   "source": [
    "### Parse the json and get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "FAEEYoypAOKA"
   },
   "outputs": [],
   "source": [
    "train_file_json = \"squad_data/data/training_set.json\"\n",
    "test_file_json = \"squad_data/data/dev-v1.1.json\"\n",
    "\n",
    "train_parser = SquadFileParser(train_file_json)\n",
    "test_parser = SquadFileParser(test_file_json)\n",
    "\n",
    "train_data = train_parser.parse_documents()\n",
    "test_data = test_parser.parse_documents()\n",
    "\n",
    "########################### DEBUG\n",
    "# reduce size for faster testing\n",
    "#full_data = data\n",
    "#data = []\n",
    "#for i in range(1): # use only the first 1 documents\n",
    "#  data.append(full_data[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SKK-4d1_93QE"
   },
   "source": [
    "### Prepare the mappers and datafram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_tokenizer_fn(question, paragraph, tokenizer, max_length=384, doc_stride=128):\n",
    "    pad_on_right = tokenizer.padding_side == \"right\"\n",
    "    # Process the sample\n",
    "    tokenized_input_pair = tokenizer(\n",
    "        question,\n",
    "        paragraph,\n",
    "        truncation=\"only_second\" if pad_on_right else \"only_first\",\n",
    "        max_length=max_length,\n",
    "        stride=doc_stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    return tokenized_input_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(params_dict[\"tokenizer_url\"])\n",
    "tokenizer_fn_preprocess = partial(bert_tokenizer_fn, tokenizer=tokenizer, max_length=params_dict[\"tokenizer_max_length\"]-3)\n",
    "tokenizer_fn_train = partial(bert_tokenizer_fn, tokenizer=tokenizer, max_length=params_dict[\"tokenizer_max_length\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import transformers\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "from tqdm import tqdm\n",
    "from transformers.optimization import AdamW\n",
    "\n",
    "from models.utils import SpanExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The device is cuda\n",
      "Automatic Mixed Precision Enabled: True\n"
     ]
    }
   ],
   "source": [
    "use_amp = True\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"The device is {device}\")\n",
    "print(f\"Automatic Mixed Precision Enabled: {use_amp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model:\n",
    "\n",
    "(input_ids, attention_mask) -> (answer_start, answer_end) // for each token in input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParametricBertModelQA(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_size, num_labels, config_dict, dropout_rate=0.3):\n",
    "        super(ParametricBertModelQA, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_labels = num_labels\n",
    "        self.bert = transformers.AutoModel.from_pretrained(config_dict[\"model_url\"])#(bert_config)\n",
    "        self.bert_drop = torch.nn.Dropout(dropout_rate)\n",
    "        self.qa_outputs = torch.nn.Linear(self.hidden_size, self.num_labels)\n",
    "        self.prepare_input_fn = config_dict[\"prepare_model_input_fn\"]\n",
    "\n",
    "    #@torch.cuda.amp.autocast() # goes OOM for whatever reason, don't use.\n",
    "    def forward(self, inputs):\n",
    "        # --- 1) Extract data from inputs dictionary and put it on right device\n",
    "        curr_device = self.bert.device\n",
    "        # --- 2) Run BERT backbone to produce final representation\n",
    "        input_dict_for_bert = self.prepare_input_fn(inputs, curr_device)\n",
    "        output = self.bert(**input_dict_for_bert)\n",
    "        # --- 3) On top of the final representation, run a mapper to get scores for each position.\n",
    "        sequence_output = output[0]   #(None, seq_len, hidden_size)\n",
    "        # do dropout\n",
    "        sequence_output = self.bert_drop(sequence_output)\n",
    "        logits = self.qa_outputs(sequence_output) #(None, seq_len, hidden_size)*(hidden_size, 2)=(None, seq_len, 2)\n",
    "        start_logits, end_logits = logits.split(1, dim=-1)    #(None, seq_len, 1), (None, seq_len, 1)\n",
    "        start_logits = start_logits.squeeze(-1)  #(None, seq_len)\n",
    "        end_logits = end_logits.squeeze(-1)    #(None, seq_len)\n",
    "        # --- 4) Prepare output tuple\n",
    "        outputs = (start_logits, end_logits,) \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define baseline model\n",
    "model = ParametricBertModelQA(768, 2, params_dict, dropout_rate=params_dict[\"train_params\"][\"dropout_rate\"]).to(device)\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=use_amp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uncomment below line to load model from disk\n",
    "model.load_state_dict(torch.load(\"trained_models/distilroberta_google_2_epochs.pt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantitative evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_paragraphs_mapper, test_df = build_mappers_and_dataframe_bert_eval(tokenizer, tokenizer_fn_preprocess, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test_QA = CustomQADatasetBERT_eval(tokenizer_fn_train, test_df, test_paragraphs_mapper)\n",
    "test_data_loader = torch.utils.data.DataLoader(\n",
    "    dataset_test_QA, collate_fn = bert_padder_collate_fn_eval, \n",
    "    batch_size=params_dict[\"train_params\"][\"batch_size_test\"], shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1350/1350 [00:50<00:00, 26.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"exact\": 80.34058656575213,\n",
      "  \"f1\": 87.68012325520641,\n",
      "  \"total\": 10570,\n",
      "  \"HasAns_exact\": 80.34058656575213,\n",
      "  \"HasAns_f1\": 87.68012325520641,\n",
      "  \"HasAns_total\": 10570\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "with open(test_file_json, \"r\") as f:\n",
    "    dataset_json = json.load(f)\n",
    "pred_dict = build_evaluation_dict_bert(model, scaler, test_data_loader, test_paragraphs_mapper, tokenizer, device, show_progress=True)\n",
    "eval_results = evaluate_predictions(dataset_json, pred_dict)\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple qualitative evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer_span_helper(context, question, model, tokenizer_fn, tokenizer, device=\"cpu\"):\n",
    "    tokenized_input = tokenizer_fn(question, context)\n",
    "    output_span = model({\n",
    "        \"input_ids\": torch.tensor(tokenized_input[\"input_ids\"]).to(device), \n",
    "        \"attention_mask\": torch.tensor(tokenized_input[\"attention_mask\"]).to(device)\n",
    "    })\n",
    "    start, end = SpanExtractor.extract_most_probable(output_span[0], output_span[1])\n",
    "    start = start.item()\n",
    "    end = end.item()\n",
    "    return tokenizer.decode(tokenized_input[\"input_ids\"][0][start:end], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"This is a test message, written to see if our model can correctly predict its outputs.\"\n",
    "question = \"Who needs to predict its outputs?\"\n",
    "pred_answer = get_answer_span_helper(context, question, model, tokenizer_fn_train, tokenizer, device=\"cuda\")\n",
    "print(pred_answer)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "NLP_Project.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "squad_qa_pytorch",
   "language": "python",
   "name": "squad_qa_pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
