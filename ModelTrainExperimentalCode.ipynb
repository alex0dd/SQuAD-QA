{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/alexpod1000/SQuAD-QA/blob/main/ModelTrainExperimentalCode.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "oTkVfFrJ-pzG"
   },
   "outputs": [],
   "source": [
    "#%%bash\n",
    "#[[ ! -e /colabtools ]] && exit  # Continue only if running on Google Colab\n",
    "\n",
    "# Clone repository\n",
    "# https://sysadmins.co.za/clone-a-private-github-repo-with-personal-access-token/\n",
    "# For cloning the main branch:\n",
    "#!git clone https://fb5b65b126107273e595ce8b6c9d2d533103c6e2:x-oauth-basic@github.com/alexpod1000/SQuAD-QA.git\n",
    "# For cloning the \"evaluation-features\" branch\n",
    "#!git clone --branch evaluation-features https://fb5b65b126107273e595ce8b6c9d2d533103c6e2:x-oauth-basic@github.com/alexpod1000/SQuAD-QA.git\n",
    "# Change current working directory to match project\n",
    "#%cd SQuAD-QA/\n",
    "#!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "rsBVuJu6_5qN"
   },
   "outputs": [],
   "source": [
    "# External imports\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import torch\n",
    "\n",
    "from nltk.tokenize import TreebankWordTokenizer, SpaceTokenizer\n",
    "from typing import Tuple, List, Dict, Any, Union\n",
    "\n",
    "# Project imports\n",
    "from squad_data.parser import SquadFileParser\n",
    "from squad_data.utils import build_mappers_and_dataframe, add_paragraphs_spans\n",
    "from evaluation.evaluation_metrics import Evaluator\n",
    "from evaluation.utils import extract_answer, build_evaluation_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "387a021D9piE"
   },
   "source": [
    "### Download Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xFweP2uIJg8O",
    "outputId": "7bb5b9ca-7b89-4fad-dc90-c979f6ef5f0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-downloaded embeddings from /home/alexpod/uni/magistrale_ai/secondo_anno/nlp/project/SQuAD-QA/embedding_models/embedding_model.kv\n",
      "End!\n",
      "Embedding dimension: 300\n"
     ]
    }
   ],
   "source": [
    "from utils.embedding_utils import EmbeddingDownloader\n",
    "\n",
    "embedding_downloader = EmbeddingDownloader(\n",
    "    \"embedding_models\", \n",
    "    \"embedding_model.kv\", \n",
    "    model_name=\"fasttext-wiki-news-subwords-300\"\n",
    ")\n",
    "\n",
    "embedding_model = embedding_downloader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Rh4dSW-9tYm"
   },
   "source": [
    "### Parse the json and get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "FAEEYoypAOKA"
   },
   "outputs": [],
   "source": [
    "parser = SquadFileParser(\"squad_data/data/training_set.json\")\n",
    "data = parser.parse_documents()\n",
    "\n",
    "########################### DEBUG\n",
    "# reduce size for faster testing\n",
    "#full_data = data\n",
    "#data = []\n",
    "#for i in range(1): # use only the first 1 documents\n",
    "#  data.append(full_data[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SKK-4d1_93QE"
   },
   "source": [
    "### Prepare the mappers and datafram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 263
    },
    "id": "x-y1GLEZJPvA",
    "outputId": "20f8a400-7f2a-406f-cd8d-87dd5698559d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?\n",
      "Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paragraph_id</th>\n",
       "      <th>question_id</th>\n",
       "      <th>answer_id</th>\n",
       "      <th>answer_start</th>\n",
       "      <th>answer_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_0</td>\n",
       "      <td>5733be284776f41900661182</td>\n",
       "      <td>0</td>\n",
       "      <td>515</td>\n",
       "      <td>Saint Bernadette Soubirous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_0</td>\n",
       "      <td>5733be284776f4190066117f</td>\n",
       "      <td>0</td>\n",
       "      <td>188</td>\n",
       "      <td>a copper statue of Christ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_0</td>\n",
       "      <td>5733be284776f41900661180</td>\n",
       "      <td>0</td>\n",
       "      <td>279</td>\n",
       "      <td>the Main Building</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_0</td>\n",
       "      <td>5733be284776f41900661181</td>\n",
       "      <td>0</td>\n",
       "      <td>381</td>\n",
       "      <td>a Marian place of prayer and reflection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0_0</td>\n",
       "      <td>5733be284776f4190066117e</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "      <td>a golden statue of the Virgin Mary</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  paragraph_id               question_id  answer_id  answer_start  \\\n",
       "0          0_0  5733be284776f41900661182          0           515   \n",
       "1          0_0  5733be284776f4190066117f          0           188   \n",
       "2          0_0  5733be284776f41900661180          0           279   \n",
       "3          0_0  5733be284776f41900661181          0           381   \n",
       "4          0_0  5733be284776f4190066117e          0            92   \n",
       "\n",
       "                               answer_text  \n",
       "0               Saint Bernadette Soubirous  \n",
       "1                a copper statue of Christ  \n",
       "2                        the Main Building  \n",
       "3  a Marian place of prayer and reflection  \n",
       "4       a golden statue of the Virgin Mary  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraphs_mapper, questions_mapper, df = build_mappers_and_dataframe(data)\n",
    "print(questions_mapper[next(iter(questions_mapper))])\n",
    "print(paragraphs_mapper[next(iter(paragraphs_mapper))])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = paragraphs_mapper[next(iter(paragraphs_mapper))]\n",
    "qq = questions_mapper[next(iter(questions_mapper))]\n",
    "aa = df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import MWETokenizer, TreebankWordTokenizer\n",
    "\n",
    "mwe = MWETokenizer(separator='')\n",
    "mwe.add_mwe(('<', 'ANS_START', '>'))\n",
    "mwe.add_mwe(('<', 'ANS_END', '>'))\n",
    "\n",
    "start_indicator = \"<ANS_START>\"\n",
    "end_indicator = \"<ANS_END>\"\n",
    "\n",
    "def add_in_middle(string, pos, to_add):\n",
    "    \"\"\"\n",
    "    Given a string, a position and a substring, \n",
    "    adds the substring at position index of the string.\n",
    "    \"\"\"\n",
    "    return string[:pos] + to_add + string[pos:]\n",
    "\n",
    "def augment_string(string, answer_start_idx, answer_end_idx):\n",
    "    \"\"\"\n",
    "    Given a string, adds the start and end indicators at right indexes\n",
    "    \"\"\"\n",
    "    start_aug = add_in_middle(string, answer_start_idx, start_indicator)\n",
    "    end_aug = add_in_middle(start_aug, len(start_indicator) + answer_end_idx, end_indicator)\n",
    "    return end_aug\n",
    "\n",
    "def get_indexes_from_augmented_string(string):\n",
    "    tokenized_aug = mwe.tokenize(tokenizer.tokenize(string))\n",
    "    # get start of answer span index\n",
    "    index_of_start_indicator = tokenized_aug.index(start_indicator)\n",
    "    # remove index from string (now it will coincide with span start)\n",
    "    tokenized_aug.pop(index_of_start_indicator)\n",
    "    # same procedure for the end of span\n",
    "    index_of_end_indicator = tokenized_aug.index(end_indicator)\n",
    "    tokenized_aug.pop(index_of_end_indicator)\n",
    "    index_of_end_indicator -= 1\n",
    "    return tokenized_aug, (index_of_start_indicator, index_of_end_indicator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['is']\n"
     ]
    }
   ],
   "source": [
    "text = \"This is good\"\n",
    "ans_start_idx = 5\n",
    "ans_end_idx = 7 # start + len\n",
    "au = augment_string(text, ans_start_idx, ans_end_idx)\n",
    "tokenized_str, ans_span_idxs = get_indexes_from_augmented_string(au)\n",
    "print(tokenized_str[ans_span_idxs[0]:ans_span_idxs[1]+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to <ANS_START>Saint Bernadette Soubirous<ANS_END> in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.'"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#augment_string(pp, aa[\"answer_start\"], aa[\"answer_start\"] + len(aa[\"answer_text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "eee = \"This <ANS_START>is<ANS_END> good\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text_dict: Dict[str, Any], text_key: Union[str, None] = None) -> Any:\n",
    "    text_dict = copy.deepcopy(text_dict)\n",
    "    # just tokenize and remove punctuation for now\n",
    "    # TODO: add better punctuation removal later\n",
    "    tokenizer = SpaceTokenizer()#TreebankWordTokenizer()\n",
    "    for key in text_dict.keys():\n",
    "        if text_key is not None:\n",
    "            text = tokenizer.tokenize(text_dict[key][text_key])\n",
    "            text_dict[key][text_key] = text\n",
    "        else:\n",
    "            text = tokenizer.tokenize(text_dict[key])\n",
    "            text_dict[key] = text\n",
    "    return text_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraphs_mapper = preprocess_text(paragraphs_mapper)\n",
    "questions_mapper = preprocess_text(questions_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "5hpoaGpK4qYe"
   },
   "outputs": [],
   "source": [
    "# Extend the paragraphs mapper to include spans\n",
    "paragraphs_spans_mapper = add_paragraphs_spans(paragraphs_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E02_XWu_4qYe",
    "outputId": "9d318e81-3fac-4d9c-b214-865708f5c71d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Architecturally,', 'the', 'school', 'has', 'a', 'Catholic', 'character.', 'Atop', 'the', 'Main', \"Building's\", 'gold', 'dome', 'is', 'a', 'golden', 'statue', 'of', 'the', 'Virgin', 'Mary.', 'Immediately', 'in', 'front', 'of', 'the', 'Main', 'Building', 'and', 'facing', 'it,', 'is', 'a', 'copper', 'statue', 'of', 'Christ', 'with', 'arms', 'upraised', 'with', 'the', 'legend', '\"Venite', 'Ad', 'Me', 'Omnes\".', 'Next', 'to', 'the', 'Main', 'Building', 'is', 'the', 'Basilica', 'of', 'the', 'Sacred', 'Heart.', 'Immediately', 'behind', 'the', 'basilica', 'is', 'the', 'Grotto,', 'a', 'Marian', 'place', 'of', 'prayer', 'and', 'reflection.', 'It', 'is', 'a', 'replica', 'of', 'the', 'grotto', 'at', 'Lourdes,', 'France', 'where', 'the', 'Virgin', 'Mary', 'reputedly', 'appeared', 'to', 'Saint', 'Bernadette', 'Soubirous', 'in', '1858.', 'At', 'the', 'end', 'of', 'the', 'main', 'drive', '(and', 'in', 'a', 'direct', 'line', 'that', 'connects', 'through', '3', 'statues', 'and', 'the', 'Gold', 'Dome),', 'is', 'a', 'simple,', 'modern', 'stone', 'statue', 'of', 'Mary.']\n",
      "[(0, 16), (17, 20), (21, 27), (28, 31), (32, 33), (34, 42), (43, 53), (54, 58), (59, 62), (63, 67), (68, 78), (79, 83), (84, 88), (89, 91), (92, 93), (94, 100), (101, 107), (108, 110), (111, 114), (115, 121), (122, 127), (128, 139), (140, 142), (143, 148), (149, 151), (152, 155), (156, 160), (161, 169), (170, 173), (174, 180), (181, 184), (185, 187), (188, 189), (190, 196), (197, 203), (204, 206), (207, 213), (214, 218), (219, 223), (224, 232), (233, 237), (238, 241), (242, 248), (249, 256), (257, 259), (260, 262), (263, 270), (271, 275), (276, 278), (279, 282), (283, 287), (288, 296), (297, 299), (300, 303), (304, 312), (313, 315), (316, 319), (320, 326), (327, 333), (334, 345), (346, 352), (353, 356), (357, 365), (366, 368), (369, 372), (373, 380), (381, 382), (383, 389), (390, 395), (396, 398), (399, 405), (406, 409), (410, 421), (422, 424), (425, 427), (428, 429), (430, 437), (438, 440), (441, 444), (445, 451), (452, 454), (455, 463), (464, 470), (471, 476), (477, 480), (481, 487), (488, 492), (493, 502), (503, 511), (512, 514), (515, 520), (521, 531), (532, 541), (542, 544), (545, 550), (551, 553), (554, 557), (558, 561), (562, 564), (565, 568), (569, 573), (574, 579), (580, 584), (585, 587), (588, 589), (590, 596), (597, 601), (602, 606), (607, 615), (616, 623), (624, 625), (626, 633), (634, 637), (638, 641), (642, 646), (647, 653), (654, 656), (657, 658), (659, 666), (667, 673), (674, 679), (680, 686), (687, 689), (690, 695)]\n"
     ]
    }
   ],
   "source": [
    "print(paragraphs_spans_mapper['0_0']['text'])\n",
    "print(paragraphs_spans_mapper['0_0']['spans'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xb4YK_Qa95zK"
   },
   "source": [
    "### DataConverter and CustomQADataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KDl4CIW-mj_D",
    "outputId": "f012b0d4-f66e-4917-c208-1ebebe9a2f23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 226, 300])\n",
      "torch.Size([10, 2])\n"
     ]
    }
   ],
   "source": [
    "from data_loading.utils import DataConverter, padder_collate_fn\n",
    "from data_loading.qa_dataset import CustomQADataset\n",
    "\n",
    "data_converter = DataConverter(embedding_model, paragraphs_mapper)\n",
    "datasetQA = CustomQADataset(data_converter, df, paragraphs_mapper, questions_mapper)\n",
    "data_loader = torch.utils.data.DataLoader(datasetQA, collate_fn = padder_collate_fn, batch_size=10, shuffle=True)\n",
    "\n",
    "test_batch = next(iter(data_loader))\n",
    "print(test_batch[\"paragraph_emb\"].shape)\n",
    "print(test_batch[\"y_gt\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 83,  91],\n",
       "        [ 96, 101],\n",
       "        [ 62,  64],\n",
       "        [ 17,  18],\n",
       "        [  3,   3],\n",
       "        [ 37,  42],\n",
       "        [  4,   5],\n",
       "        [ 87,  91],\n",
       "        [ 65,  76],\n",
       "        [  8,   8]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_batch[\"y_gt\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The device is cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"The device is {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model:\n",
    "\n",
    "(paragraph_emb, question_emb) -> (answer_start, answer_end) // for each token in paragraph_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, optimizer, loss_function, dataloader, device=\"cpu\"):\n",
    "    acc_loss = 0\n",
    "    acc_start_accuracy = 0\n",
    "    acc_end_accuracy = 0\n",
    "    count = 0\n",
    "\n",
    "    time_start = timer()\n",
    "    \n",
    "    model.train()\n",
    "    for batch in dataloader:\n",
    "        paragraph_in = batch[\"paragraph_emb\"]\n",
    "        question_in = batch[\"question_emb\"]\n",
    "        answer_spans_start = batch[\"y_gt\"][:, 0]\n",
    "        answer_spans_end = batch[\"y_gt\"][:, 1]\n",
    "        # Clear gradients\n",
    "        model.zero_grad()\n",
    "        # Place to right device\n",
    "        paragraph_in = paragraph_in.to(device)\n",
    "        question_in = question_in.to(device)\n",
    "        answer_spans_start = answer_spans_start.to(device)\n",
    "        answer_spans_end = answer_spans_end.to(device)\n",
    "        # Run forward pass\n",
    "        pred_answer_start_scores, pred_answer_end_scores = model(paragraph_in, question_in)\n",
    "        # Compute the CrossEntropyLoss\n",
    "        loss = loss_function(pred_answer_start_scores, answer_spans_start) + loss_function(pred_answer_end_scores, answer_spans_end)\n",
    "        # Compute gradients\n",
    "        loss.backward()\n",
    "        # Optimizer step\n",
    "        optimizer.step()\n",
    "        # --- Compute metrics ---\n",
    "        # Get span indexes\n",
    "        pred_span_start_idxs, pred_span_end_idxs = model.estimate_best_span(pred_answer_start_scores, pred_answer_end_scores)\n",
    "        #pred_span_start_idxs = torch.argmax(pred_answer_start_scores, axis=-1).cpu().detach()\n",
    "        #pred_span_end_idxs = torch.argmax(pred_answer_end_scores, axis=-1).cpu().detach()\n",
    "        gt_start_idxs = answer_spans_start.cpu().detach()\n",
    "        gt_end_idxs = answer_spans_end.cpu().detach()\n",
    "        # two accs\n",
    "        start_accuracy = torch.sum(gt_start_idxs == pred_span_start_idxs) / len(pred_span_start_idxs)\n",
    "        end_accuracy = torch.sum(gt_end_idxs == pred_span_end_idxs) / len(pred_span_end_idxs)\n",
    "        # Gather stats\n",
    "        acc_loss += loss.item()\n",
    "        acc_start_accuracy += start_accuracy.item()\n",
    "        acc_end_accuracy += end_accuracy.item()\n",
    "        count += 1\n",
    "    time_end = timer()\n",
    "    return {\n",
    "        \"loss\": acc_loss / count, \n",
    "        \"accuracy_start\": acc_start_accuracy / count, \n",
    "        \"accuracy_end\": acc_end_accuracy / count,\n",
    "        \"time\": time_end - time_start\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Evaluator object\n",
    "evaluator = Evaluator(documents_list=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_on_data(model, evaluator, dataloader, paragraphs_mapper, questions_mapper, device, debug=False):\n",
    "    eval_dict = build_evaluation_dict(model, dataloader, paragraphs_mapper, questions_mapper, device)\n",
    "    if debug:\n",
    "        print(f\"DEBUG: Eval_dict: {eval_dict}\")\n",
    "    stats = {}\n",
    "    stats['exact_match'] = evaluator.ExactMatch(eval_dict)\n",
    "    stats['f1'] = evaluator.F1(eval_dict)\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedSum(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        \"\"\"\n",
    "        General idea, given a random dummy weights vector, \n",
    "        learn to weight it based on query\n",
    "        \"\"\"\n",
    "        super(WeightedSum, self).__init__()\n",
    "        self.weights = nn.Parameter(torch.randn(input_dim))\n",
    "\n",
    "    def forward(self, input_emb, mask=None):\n",
    "        # TODO: if needed, implement time masking\n",
    "        batch, timesteps, embed_dim = input_emb.shape\n",
    "        # w dot q_j\n",
    "        dot_prods = torch.matmul(input_emb, self.weights)\n",
    "        # exp(w dot q_j)\n",
    "        exp_prods = torch.exp(dot_prods)\n",
    "        # normalization factor\n",
    "        sum_exp_prods = torch.sum(exp_prods, dim=1)\n",
    "        sum_exp_prods = sum_exp_prods.repeat(timesteps, 1).T\n",
    "        # b_j\n",
    "        b = exp_prods / sum_exp_prods\n",
    "        # q (embedding) = sum_t(b_t * q_t)\n",
    "        b_scal_q = input_emb * b[:, :, None]\n",
    "        # now sum along correct axis\n",
    "        q = torch.sum(b_scal_q, axis=1)\n",
    "        return q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compatibility functions**\n",
    "\n",
    "**Multiplicative (dot)**:\n",
    "\n",
    "p = paragraph emb shape: [B, T, E] (Query)\n",
    "\n",
    "q = question weighted shape: [B, E] reshaped to [B, E, 1] (Keys)\n",
    "\n",
    "scores = p @ q (of shape: [B, T, 1])\n",
    "\n",
    "**General bilinear**:\n",
    "\n",
    "p = paragraph emb shape: [B, T, Ep] (Query)\n",
    "\n",
    "q = question weighted shape: [B, Eq] reshaped to [B, Eq, 1] (Keys)\n",
    "\n",
    "W = parameter matrix of shape: [Ep, Eq]\n",
    "\n",
    "scores = p @ W @ q (of shape: [B, T, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BilinearCompatibility(nn.Module):\n",
    "    def __init__(self, query_dim, keys_dim):\n",
    "        \"\"\"\n",
    "        Perform bilinear compatibility f(q, K) = q.T @ W @ K\n",
    "        Recall: multiplicative/dot compatibility is f(q, K) = q.T @ K\n",
    "        \n",
    "        Where: \n",
    "            q -> embedded paragraphs (p in DrQA)\n",
    "            K -> embedded question (q in DrQA)\n",
    "        \"\"\"\n",
    "        super(BilinearCompatibility, self).__init__()\n",
    "        self.weights = nn.Parameter(torch.randn(query_dim, keys_dim))\n",
    "\n",
    "    def forward(self, query, keys):\n",
    "        \"\"\"\n",
    "        query: batch of shape (batch, seq_len, query_dim) (Query)\n",
    "        keys = batch of shape (batch, key_dim) which will be reshaped into [batch, key_dim, 1] (Keys)\n",
    "        \"\"\"\n",
    "        return query @ self.weights @ keys[:, :, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_QA(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim, tagset_size):\n",
    "        super(LSTM_QA, self).__init__()\n",
    "        self.tagset_size = tagset_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding_dim = embedding_dim\n",
    "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
    "        # with dimensionality hidden_dim.\n",
    "        self.paragraph_embedder = nn.LSTM(embedding_dim, hidden_dim, bidirectional=True, batch_first=True)\n",
    "        self.question_embedder = nn.LSTM(embedding_dim, hidden_dim, bidirectional=True, batch_first=True)\n",
    "        self.weighted_sum = WeightedSum(hidden_dim * 2)\n",
    "        # used to compute similarity scores\n",
    "        self.general_bilinear_start = BilinearCompatibility(hidden_dim * 2, hidden_dim * 2)\n",
    "        self.general_bilinear_end = BilinearCompatibility(hidden_dim * 2, hidden_dim * 2)\n",
    "        # to classify from similarity to prob of start and prob of end\n",
    "        self.sim_to_start = nn.Linear(1, 1) # given a similarity score, predict P(start)\n",
    "        self.sim_to_end = nn.Linear(1, 1) # given a similarity score, predict P(end)\n",
    "        \n",
    "    def estimate_best_span(self, start_scores, end_scores):\n",
    "        #pred_start_idxs = torch.argmax(pred_start_scores, axis=-1).cpu().detach()\n",
    "        #pred_end_idxs = torch.argmax(pred_end_scores, axis=-1).cpu().detach()\n",
    "\n",
    "        batch_dim, timestep_dim = start_scores.shape\n",
    "\n",
    "        # compute marginal distributions for start and end\n",
    "        start_probs = torch.nn.functional.softmax(start_scores, dim=1)\n",
    "        end_probs = torch.nn.functional.softmax(end_scores, dim=1)\n",
    "        # compute start_end joint distribution\n",
    "        joint_dist_start_end = start_probs[:, :, None] @ end_probs[:, None, :]# end_probs\n",
    "        constrained_joint_dist = torch.triu(joint_dist_start_end)\n",
    "        # compute the actual indexes\n",
    "        flattened_distr_argmax = constrained_joint_dist.view(batch_dim, -1).argmax(1).view(-1, 1)\n",
    "        start_end_idxs = torch.cat((flattened_distr_argmax // timestep_dim, flattened_distr_argmax % timestep_dim), dim=1).cpu().detach()#.numpy()\n",
    "        return start_end_idxs[:, 0], start_end_idxs[:, 1]\n",
    "\n",
    "    def forward(self, paragraphs, questions):\n",
    "        batch_size, seq_len, n_feat = paragraphs.shape\n",
    "        # As we assume batch_first true, then our sentence_embeddings will have correct shape\n",
    "        paragraphs_seq_emb, _ = self.paragraph_embedder(paragraphs) # (batch, seq_len, n_feats * n_dirs)\n",
    "        questions_seq_emb, _ = self.question_embedder(questions) # (batch, seq_len, n_feats * n_dirs)\n",
    "        # weighted sum\n",
    "        questions_state_repr = self.weighted_sum(questions_seq_emb)\n",
    "        #return paragraphs_seq_emb, questions_state_repr\n",
    "        # compute similarities -> (batch, timestep, 1)\n",
    "        similarities_start = self.general_bilinear_start(paragraphs_seq_emb, questions_state_repr)\n",
    "        similarities_end = self.general_bilinear_end(paragraphs_seq_emb, questions_state_repr)\n",
    "        #print(f\"INSIDE MODEL: similarities shape: {similarities.shape}\") #DEBUG\n",
    "        # --- Given a similarity score, predict P(start), P(end) ---\n",
    "        # similarities flattened\n",
    "        similarities_start = similarities_start.contiguous()\n",
    "        similarities_start = similarities_start.view(-1, 1) # as similarity dim is 1 -> viewed shape is (batch*timestep, 1)\n",
    "        start_scores = self.sim_to_start(similarities_start)\n",
    "        start_logits = start_scores.view(batch_size, seq_len) # P(start)\n",
    "        \n",
    "        similarities_end = similarities_end.contiguous()\n",
    "        similarities_end = similarities_end.view(-1, 1) # as similarity dim is 1 -> viewed shape is (batch*timestep, 1)\n",
    "        end_scores = self.sim_to_end(similarities_end)\n",
    "        end_logits = end_scores.view(batch_size, seq_len) # P(end)\n",
    "        \n",
    "        # if we view each sequence of tokens as a feature vector\n",
    "        # we can interpret the start/end assignation problem as \n",
    "        # a classification with a variable number of classes\n",
    "        # thus assume that our model outputs logits that will just be passed\n",
    "        # to a softmax, to build a probable distribution of the start token\n",
    "        return start_logits, end_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.nn.functional.softmax(outs_mod[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define baseline model\n",
    "model = LSTM_QA(embedding_model.vector_size, 128, 10).to(device)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01, weight_decay=0.0001, amsgrad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_converter = DataConverter(embedding_model, paragraphs_mapper)\n",
    "datasetQA = CustomQADataset(data_converter, df, paragraphs_mapper, questions_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader = torch.utils.data.DataLoader(datasetQA, collate_fn = padder_collate_fn, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "treebank_tokenizer = TreebankWordTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph_in = batch[\"paragraph_emb\"]\n",
    "question_in = batch[\"question_emb\"]\n",
    "answer_spans_start = batch[\"y_gt\"][:, 0]\n",
    "answer_spans_end = batch[\"y_gt\"][:, 1]\n",
    "paragraph_id = batch[\"paragraph_id\"]\n",
    "question_id = batch[\"question_id\"]\n",
    "# Place to right device\n",
    "paragraph_in = paragraph_in.to(device)\n",
    "question_in = question_in.to(device)\n",
    "answer_spans_start = answer_spans_start.to(device)\n",
    "answer_spans_end = answer_spans_end.to(device)\n",
    "# Run forward pass\n",
    "pred_answer_start_scores, pred_answer_end_scores = model(paragraph_in, question_in)\n",
    "# Get span indexes\n",
    "pred_span_start_idxs, pred_span_end_idxs = model.estimate_best_span(pred_answer_start_scores, pred_answer_end_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dict = {}\n",
    "for sample_idx in range(len(paragraph_id)):\n",
    "    paragraph_sample_id = paragraph_id[sample_idx]\n",
    "    question_sample_id = question_id[sample_idx]\n",
    "    pred_span_start_sample = pred_span_start_idxs[sample_idx]\n",
    "    pred_span_end_sample = pred_span_end_idxs[sample_idx]\n",
    "    par_tokens = treebank_tokenizer.tokenize(paragraphs_mapper[paragraph_sample_id])\n",
    "    pred_answer_text = extract_answer(par_tokens,\n",
    "                                      pred_span_start_sample,\n",
    "                                      pred_span_end_sample)\n",
    "    # add new (question_id, pred_answer_text) to the eval dict:\n",
    "    eval_dict[question_sample_id] = pred_answer_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What were the protesters on September 2 demonstrating against?'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions_mapper['572820d23acd2414000df517']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'571a7b2b10f8ca1400305099': 'Hasidic and',\n",
       " '572c9ab3dfb02c14005c6bae': '`` living law',\n",
       " '573223cce17f3d14004226b5': 'independent',\n",
       " '572ed854dfa6aa1500f8d446': \"Several sources indicate that during Muhammad 's lifetime a large number of his companions had memorized the\",\n",
       " '573425624776f41900661959': '13',\n",
       " '5727f2f53acd2414000df09b': 'Latin',\n",
       " '572f21aea23a5019007fc4ac': 'revolutionary',\n",
       " '56d62ca31c85041400946f74': \"trying to achieve status '' is characteristic of dog–human interactions. Pet dogs play an active role in family\",\n",
       " '57094c819928a81400471502': \"industry–led boom in 1970. A succession of skyscrapers were built throughout the 1970s—many by real estate developer Gerald D. Hines—culminating with Houston 's tallest skyscraper , the 75-floor , 1,002-foot ( 305 m ) -tall JPMorgan Chase Tower ( formerly the Texas Commerce\",\n",
       " '5726866b5951b619008f758f': 'me (',\n",
       " '56df7fd95ca0a614008f9b6f': 'Street',\n",
       " '571a87714faf5e1900b8aa17': 'Persians.',\n",
       " '57095ba39928a81400471548': 'foreclosed or',\n",
       " '5706b5100eeca41400aa0d69': 'hip-hop influences evident in the quicker sampling and the more rugged',\n",
       " '572f52bc04bcaa1900d7684c': '1976.',\n",
       " '56de7613cffd8e1900b4b947': 'King George VI and Queen',\n",
       " '572743c45951b619008f8798': \"German Reformation by posting 95 theses on the castle church of Wittenberg on October 31 , 1517. The immediate provocation spurring this act was Pope Leo X’s renewal of the indulgence for the building of the new St. Peter 's Basilica in 1514. Luther was challenged to recant his heresy at the Diet of Worms in 1521. When he refused , he was placed under the ban of the Empire by Charles V. Receiving the protection of Frederick the Wise , he was then able to translate the Bible into\",\n",
       " '56f6f7d73d8e2e1400e372fc': 'woodwind',\n",
       " '5735c1dedc94161900571fbe': 'Lord',\n",
       " '572ed315cb0c0d14000f15ea': 'The loss of Kolberg cost Prussia its last port on the Baltic Sea. In Britain , it was speculated that a total Prussian collapse was now imminent',\n",
       " '572ed16f03f9891900756a4d': \"Wang Mang , the state of Goguryeo was free to raid Han 's Korean commanderies ; Han did not reaffirm its control over the region until AD 30. The Trưng Sisters of Vietnam rebelled against Han in AD 40. Their rebellion was crushed by Han general Ma\",\n",
       " '572fe6e3a23a5019007fcb11': '1925.',\n",
       " '572bb6bc34ae481900deaee1': 'three berths capable of hosting vessels and barges as well as the facilities required to handle break bulk cargo. The port has the capacity to load',\n",
       " '57310d2da5e9cc1400cdbbea': 'Senior',\n",
       " '5706021475f01819005e7868': 'walking.',\n",
       " '572974506aef051400154f1c': 'Secretary-General Ban',\n",
       " '56cf6e0d4df3c31400b0d789': 'Adam',\n",
       " '5734173b4776f41900661851': 'north',\n",
       " '5730991d2461fd1900a9ceef': '`` classical',\n",
       " '573027b6947a6a140053d1b7': 'File',\n",
       " '57062f3952bb891400689946': '2001.',\n",
       " '56ea94715a205f1900d6d35c': 'economic',\n",
       " '573171d105b4da19006bd19d': 'Revolutionary Intellectuals Seminar was held to bring intellectuals in line with the',\n",
       " '570632d275f01819005e7a77': 'immunity and functions of cells , organs and systems not previously associated with the immune',\n",
       " '572710e05951b619008f8579': 'Variable',\n",
       " '572f7c53947a6a140053c9ae': 'locusts',\n",
       " '56d461fc2ccc5a1400d8311a': 'October 1 ,',\n",
       " '57298edfaf94a219006aa502': 'Chemoreception',\n",
       " '5726ad33708984140094cd9a': 'Avon Fire and Rescue Service , a service which also covers Bristol and South Gloucestershire. The South Western Ambulance Service covers the entire South West of England , including all of Somerset ; prior to February 2013 the unitary districts of Somerset came under the Great Western Ambulance',\n",
       " '5727d66c3acd2414000dedcb': 'June.',\n",
       " '5733926d4776f41900660d91': 'Hall of Liberal',\n",
       " '5731df9ae99e3014001e6386': 'Evangelical',\n",
       " '5706268775f01819005e7a01': 'Lyndon',\n",
       " '5735b2a8dc94161900571f39': 'seven',\n",
       " '572fa66704bcaa1900d76b3a': 'as',\n",
       " '5724d7b50a492a1900435640': '82 years',\n",
       " '5726baf15951b619008f7c24': 'local property',\n",
       " '57317f97e6313a140071cfcc': 'Lazarium',\n",
       " '5726a1ccf1498d1400e8e56b': 'cider.',\n",
       " '56dddd6766d3e219004dad45': '1582',\n",
       " '572820d23acd2414000df517': 'Communist',\n",
       " '56df0adf3277331400b4d907': 'CG634',\n",
       " '573254c7e17f3d1400422885': 'Bronx',\n",
       " '5727cd6e2ca10214002d96ca': 'laser turntable eliminates record wear and the possibility of accidental scratches , which degrade the sound , but its expense limits use primarily to digital archiving of analog records , and the laser does not play back colored vinyl or picture discs. Various other laser-based turntables were tried during the 1990s , but while a laser reads the groove very accurately , since it does not touch the record , the dust that vinyl attracts due to static electric charge is not mechanically pushed out of the groove , worsening sound quality in casual use compared to conventional stylus',\n",
       " '5726c4fbdd62a815002e8fe2': '1976',\n",
       " '572ecc0fcb0c0d14000f1581': 'Gulf of',\n",
       " '56e17248cd28a01900c6794b': 'no official',\n",
       " '56df6cb85ca0a614008f9a06': 'Royal',\n",
       " '573338734776f419006607a4': 'electron collisions are said to manifest some degree of',\n",
       " '572e98d4cb0c0d14000f1325': 'northern third of the',\n",
       " '56f89db09b226e1400dd0ccd': '90',\n",
       " '571d40405efbb31900334ef6': 'Sunshine',\n",
       " '5725e0fb89a1e219009ac01c': '1830.',\n",
       " '5727fb683acd2414000df16e': 'Article'}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([149, 122,  15, 160,  49,   3,  66,  88, 116, 102,  42,  83,  34,  25,\n",
       "         75, 197,  16,  66,  97,   0,  27,  42, 160,   3,  74, 163,  68,  58,\n",
       "         76,  71, 110,   8,  67,   8,  89, 121,  27,  34,  46,  82,  98, 146,\n",
       "          7,  28,  21,  40,  73,  47,  25,  16,  10,  20,  23,  16,  88,  99,\n",
       "        115,   4,  27,  62,  79,  92,  82,   2], device='cuda:0')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_spans_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([149, 124,  17, 161,  64,   3,  67,  97, 124, 108,  44,  83,  37,  26,\n",
       "         75, 200,  17,  69,  98,  12,  27,  42, 160,   3,  75, 166,  70,  60,\n",
       "         79,  76, 122,   8,  71,  14,  89, 121,  28,  34,  50,  83, 100, 147,\n",
       "          9,  29,  22,  46,  75,  48,  30,  21,  11,  20,  25,  19,  88, 101,\n",
       "        125,   8,  27,  72,  81,  92,  84,   2], device='cuda:0')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_spans_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([149, 122,   4, 161,  64,   3,  37,  14, 124, 108,  85,  36,  37,  16,\n",
       "         75,  71,   5,  69,  12, 122,  12,   7, 160,   7,  33,  46,  70,  10,\n",
       "         79,  43,  37,  19,   4,  14, 106, 121, 130,  34,   2,  82,  10, 147,\n",
       "         58,  29,  10,  52,   9,  77,  30,  29,  30,   4,   1, 104, 106,  86,\n",
       "         87,   8,  60,  99,  60,  79,  28,   3])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_span_start_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([149, 122,   4, 161,  64,   3,  37,  14, 124, 108,  85,  36,  37,  16,\n",
       "         75,  71,   5,  69,  12, 122,  12,   7, 160,   7,  33,  46,  70,  10,\n",
       "         79,  43,  37,  19,   4,  14, 106, 121, 130,  34,   2,  82,  10, 147,\n",
       "         58,  29,  10,  52,   9,  77,  30,  29,  30,   4,   1, 104, 106,  86,\n",
       "         87,   8,  60,  99,  60,  79,  28,   3])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_span_end_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, lr: 0.01, Train loss: 6.8148,  Train acc start: 0.1455, Train acc end: 0.2215, Time: 448.5750\n",
      "Epoch: 1, lr: 0.01, Train loss: 6.4083,  Train acc start: 0.1675, Train acc end: 0.2437, Time: 448.5415\n",
      "Epoch: 2, lr: 0.01, Train loss: 5.7889,  Train acc start: 0.2327, Train acc end: 0.3104, Time: 459.5925\n",
      "Epoch: 3, lr: 0.01, Train loss: 5.2566,  Train acc start: 0.2760, Train acc end: 0.3550, Time: 461.8417\n",
      "Epoch: 4, lr: 0.01, Train loss: 4.7785,  Train acc start: 0.3265, Train acc end: 0.4022, Time: 482.4080\n",
      "Epoch: 5, lr: 0.01, Train loss: 4.5512,  Train acc start: 0.3528, Train acc end: 0.4252, Time: 496.4858\n",
      "Epoch: 6, lr: 0.01, Train loss: 4.4082,  Train acc start: 0.3696, Train acc end: 0.4419, Time: 430.5539\n",
      "Epoch: 7, lr: 0.01, Train loss: 4.3214,  Train acc start: 0.3789, Train acc end: 0.4522, Time: 428.6056\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-efa4fa5d8895>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mscheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReduceLROnPlateau\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtrain_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;31m#eval_results = evaluate_model_on_data(model, evaluator, train_data_loader, paragraphs_mapper, questions_mapper, device, debug=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mcur_lr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-60290787ffc6>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(model, optimizer, loss_function, dataloader, device)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mparagraph_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"paragraph_emb\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mquestion_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"question_emb\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/squad_qa_pytorch/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/squad_qa_pytorch/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/squad_qa_pytorch/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/squad_qa_pytorch/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/uni/magistrale_ai/secondo_anno/nlp/project/SQuAD-QA/data_loading/qa_dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mparagraph_text_aug\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manswer_spanner_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maugment_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparagraph_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswer_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswer_start\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mparagraph_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mans_span\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manswer_spanner_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexes_from_augmented_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparagraph_text_aug\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mparagraph_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_converter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_sequence_to_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparagraph_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mquestion_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquestions_mapper\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mquestion_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/uni/magistrale_ai/secondo_anno/nlp/project/SQuAD-QA/data_loading/utils.py\u001b[0m in \u001b[0;36mword_sequence_to_embedding\u001b[0;34m(self, seq)\u001b[0m\n\u001b[1;32m     81\u001b[0m                     \u001b[0memb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moovs_memory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                 \u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mencode_answer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparagraph_id\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswer_start\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswer_text\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = {\"train_loss\": [], \"train_acc_start\": [], \"train_acc_end\": []}\n",
    "loop_start = timer()\n",
    "# lr scheduler\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=5, threshold=0.01)\n",
    "for epoch in range(50):\n",
    "    train_dict = train_step(model, optimizer, loss_function, train_data_loader, device=device)\n",
    "    #eval_results = evaluate_model_on_data(model, evaluator, train_data_loader, paragraphs_mapper, questions_mapper, device, debug=False)\n",
    "    cur_lr = optimizer.param_groups[0]['lr']\n",
    "    print(f'Epoch: {epoch}, lr: {cur_lr}, Train loss: {train_dict[\"loss\"]:.4f},  Train acc start: {train_dict[\"accuracy_start\"]:.4f}, Train acc end: {train_dict[\"accuracy_end\"]:.4f}, Time: {train_dict[\"time\"]:.4f}')\n",
    "    history[\"train_loss\"].append(train_dict[\"loss\"]);history[\"train_acc_start\"].append(train_dict[\"accuracy_start\"]);history[\"train_acc_end\"].append(train_dict[\"accuracy_end\"]);\n",
    "    #history[\"val_loss\"].append(val_dict[\"loss\"]);history[\"val_acc\"].append(val_dict[\"accuracy\"]);\n",
    "    #scheduler.step(val_dict[\"loss\"])\n",
    "    #print(f\"Evaluation Results: {eval_results}\")\n",
    "loop_end = timer()\n",
    "print(f\"Elapsed time: {(loop_end - loop_start):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Might fail ['General', 'Electric', 'heavily', 'contaminated', 'the', 'Hudson', 'River', 'with', 'polychlorinated', 'biphenyls', '(PCBs)', 'between', '1947-77.', 'This', 'pollution', 'caused', 'a', 'range', 'of', 'harmful', 'effects', 'to', 'wildlife', 'and', 'people', 'who', 'eat', 'fish', 'from', 'the', 'river', 'or', 'drink', 'the', 'water.', 'In', 'response', 'to', 'this', 'contamination,', 'activists', 'protested', 'in', 'various', 'ways.', 'Musician', 'Pete', 'Seeger', 'founded', 'the', 'Hudson', 'River', 'Sloop', 'Clearwater', 'and', 'the', 'Clearwater', 'Festival', 'to', 'draw', 'attention', 'to', 'the', 'problem.', 'The', 'activism', 'led', 'to', 'the', 'site', 'being', 'designated', 'by', 'the', 'EPA', 'as', 'one', 'of', 'the', 'superfund', 'sites', 'requiring', 'extensive', 'cleanup.', 'Other', 'sources', 'of', 'pollution,', 'including', 'mercury', 'contamination', 'and', 'sewage', 'dumping,', 'have', 'also', 'contributed', 'to', 'problems', 'in', 'the', 'Hudson', 'River', 'watershed.'] len 104 start tensor(104)\n",
      "Might fail ['The', 'city', 'council', 'of', 'the', 'city', 'of', 'Bern', 'decided', 'against', 'having', 'twinned', 'cities', 'except', 'for', 'a', 'temporary', '(during', 'the', 'UEFA', 'Euro', '2008)', 'cooperation', 'with', 'the', 'Austrian', 'city', 'Salzburg'] len 28 start tensor(28)\n",
      "Might fail ['Apparently', 'the', 'sailor', 'did', 'not', 'connect', 'with', 'the', 'soldier,', 'as', 'Mahan', 'believed', 'he', 'was', 'innovating', 'the', 'term', 'Middle', 'East.', 'It', 'was,', 'however,', 'already', 'there', 'to', 'be', 'seen.'] len 27 start tensor(27)\n"
     ]
    }
   ],
   "source": [
    "eval_dict = build_evaluation_dict(model, train_data_loader, paragraphs_mapper, questions_mapper, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Of', 'what', 'ancestry', 'was', 'Napoleon?'] Corsica\n"
     ]
    }
   ],
   "source": [
    "qid = \"5725b40389a1e219009abd0a\"\n",
    "print(questions_mapper[qid], eval_dict[qid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'56f8eee09e9bad19000a0724': 'Medicine',\n",
       " '5733a8d44776f41900660f81': 'threat.[citation',\n",
       " '56bf99aca10cfb14005511ab': 'million.',\n",
       " '5733fa9a4776f41900661628': 'May',\n",
       " '56de2cf1cffd8e1900b4b61f': 'Commensal',\n",
       " '56e8d85b0b45c0140094cd0c': 'Westminster,',\n",
       " '5733b49a4776f419006610c0': 'Beira,',\n",
       " '572fafeca23a5019007fc89d': 'model.',\n",
       " '56e7b57900c9c71400d7753d': '400,000',\n",
       " '572ac493111d821400f38d49': 'Philadelphia',\n",
       " '5725c35889a1e219009abe13': 'Cross',\n",
       " '572b63a8be1ee31400cb834d': 'Airport,',\n",
       " '572fa02704bcaa1900d76b0c': 'coiled,',\n",
       " '570e45630b85d914000d7dd5': '800,000',\n",
       " '5726a652f1498d1400e8e61a': '\"As',\n",
       " '57294dda1d0469140077926e': 'JP).',\n",
       " '5731a004e99e3014001e6192': 'Obama,',\n",
       " '57284e224b864d190016490c': 'Vedanta',\n",
       " '5726d340dd62a815002e9174': 'William',\n",
       " '5726a73df1498d1400e8e630': '167.950.',\n",
       " '5726b8a5f1498d1400e8e8e1': 'Korea.',\n",
       " '56e032247aa994140058e34b': 'Cartoonists',\n",
       " '5729b86a3f37b31900478542': 'Lenovo',\n",
       " '570db4b716d0071400510d15': 'Emperor.',\n",
       " '57296bd76aef051400154e4c': 'salts,',\n",
       " '572913d3af94a219006aa041': 'loan-translation',\n",
       " '56df631296943c1400a5d4aa': 'Atlantic',\n",
       " '56d07aa6234ae51400d9c318': 'Lange,',\n",
       " '57268e0ff1498d1400e8e3a6': 'meid',\n",
       " '572673895951b619008f72f9': '2004,',\n",
       " '56e08680231d4119001ac26d': '1941,',\n",
       " '57320e760fdd8d15006c6723': 'eggs.',\n",
       " '57104598b654c5140001f8c4': 'reprehensible,',\n",
       " '57260df5ec44d21400f3d865': 'clothing.',\n",
       " '56e03c3c7aa994140058e3ee': 'border.',\n",
       " '570a059c6d058f1900182c75': 'housing,',\n",
       " '5726bb60f1498d1400e8e943': 'Perpendicular',\n",
       " '572678f9708984140094c745': 'Canaanite',\n",
       " '57302226947a6a140053d16d': '1903,',\n",
       " '572fec6f947a6a140053ce09': 'water.',\n",
       " '571dea26b64a571400c71dfa': 'category,',\n",
       " '573011bba23a5019007fccf8': '83%',\n",
       " '572d31bfb297151900c7ce87': 'rockist',\n",
       " '5727fdf64b864d1900164192': 'German,',\n",
       " '571a35774faf5e1900b8a924': 'streets,',\n",
       " '5732a188cc179a14009dabb1': '1841',\n",
       " '572eb82403f9891900756997': '92',\n",
       " '5731e2de0fdd8d15006c65ff': 'flocks.',\n",
       " '572777c3f1498d1400e8f8f0': 'Ashkenazi',\n",
       " '572fa359947a6a140053caec': 'religion.',\n",
       " '5726801fdd62a815002e875d': 'Records.',\n",
       " '5726be03f1498d1400e8e9d5': 'MacArthur',\n",
       " '56de7c7a4396321400ee295d': 'bombs',\n",
       " '571010b6a58dae1900cd6853': 'unusual\"',\n",
       " '572f44e8b2c2fd1400567fb3': '(1992)',\n",
       " '5725df1689a1e219009ac000': '12',\n",
       " '5725f343ec44d21400f3d77a': 'Ballroom,',\n",
       " '570d4faffed7b91900d45e62': '2001,',\n",
       " '57270a05708984140094d8e5': 'capacitors,',\n",
       " '5726f847f1498d1400e8f15d': 'India,',\n",
       " '56d97163dc89441400fdb47a': 'Seung-kook',\n",
       " '56e102b7cd28a01900c6742c': 'Aquinas',\n",
       " '56db70ebe7c41114004b5114': 'Party.\"',\n",
       " '57276c415951b619008f89a0': 'Hazel,',\n",
       " '56daedd8e7c41114004b4b36': '2001',\n",
       " '56cf77214df3c31400b0d7e9': 'piano,',\n",
       " '572ab2abf75d5e190021fc4f': 'white',\n",
       " '5727bfcf3acd2414000deb74': 'League,',\n",
       " '572674a4f1498d1400e8e030': 'Asia',\n",
       " '5727a7852ca10214002d92ff': 'George',\n",
       " '5727e7822ca10214002d9927': 'Tulsa,',\n",
       " '5730e84cf6cb411900e2453e': 'title,',\n",
       " '56db2841e7c41114004b4e4f': 'district,',\n",
       " '5725b87189a1e219009abd6a': 'pets.',\n",
       " '5733b463d058e614000b60c8': 'unemployment.',\n",
       " '56cf1aa6aab44d1400b88d89': '(1930)',\n",
       " '56cd97f862d2951400fa676c': 'Iwata',\n",
       " '5727ff3c4b864d19001641bf': 'purple,',\n",
       " '571001fea58dae1900cd67c7': 'others.',\n",
       " '572fc229b2c2fd1400568404': 'Dowding',\n",
       " '5733fc754776f4190066164e': 'Khan.',\n",
       " '570c3da6ec8fbc190045be0c': 'Gabriel',\n",
       " '570a61844103511400d5969c': 'noradrenaline,',\n",
       " '572fb308b2c2fd1400568377': \"'Fourth\",\n",
       " '57267b57708984140094c796': 'four',\n",
       " '56dde2609a695914005b964c': '1590–1712',\n",
       " '56cc27346d243a140015eebb': '1402–1424)',\n",
       " '573223b4e99e3014001e6545': \"Greece's\",\n",
       " '57280ab42ca10214002d9c5b': \"Egypt's\",\n",
       " '572819ff3acd2414000df48e': 'Delhi',\n",
       " '57064fcc75f01819005e7b35': 'MP3Gain',\n",
       " '572fd34a947a6a140053cd17': 'education,',\n",
       " '571a10584faf5e1900b8a880': 'dozen',\n",
       " '57292674af94a219006aa10e': 'Genetics',\n",
       " '572a5776d562191400bc8684': 'I,',\n",
       " '5723f8090dadf01500fa1fcf': 'Victoria',\n",
       " '57102369a58dae1900cd68f9': 'barbaric',\n",
       " '56cfabed234ae51400d9be49': '(transliterated',\n",
       " '570a80f26d058f1900182eda': '1992',\n",
       " '572e5cc5c246551400ce4218': '1970s.',\n",
       " '57339840d058e614000b5e4e': '\"understands',\n",
       " '56d1099d17492d1400aab7c4': 'hop,',\n",
       " '56f7083a711bf01900a448fa': 'resolved.',\n",
       " '5728bc93ff5b5019007da5ba': 'dragonfly-like',\n",
       " '56d3971459d6e414001467ce': '1937',\n",
       " '57345b47879d6814001ca54d': 'Lines,',\n",
       " '572803422ca10214002d9b75': 'time?',\n",
       " '5726bce2f1498d1400e8e99e': '49',\n",
       " '5723d221f6b826140030fc95': '82',\n",
       " '56fb92688ddada1400cd6502': 'cities.',\n",
       " '571a79a64faf5e1900b8a9bd': 'law.',\n",
       " '57262c83ec44d21400f3db94': 'cooled,',\n",
       " '5727e2e12ca10214002d98a2': 'atmospheres,',\n",
       " '572f19dc03f9891900756b8f': 'Ferdinand',\n",
       " '5726b85cf1498d1400e8e8da': 'colleges.',\n",
       " '570a84444103511400d597f2': 'Dock',\n",
       " '56df2305c65bf219000b3f97': 'Records,',\n",
       " '56f75316a6d7ea1400e171b7': \"Bros.'\",\n",
       " '570d2681fed7b91900d45c63': '1775',\n",
       " '5730168bb2c2fd140056883b': 'November',\n",
       " '57268ff4dd62a815002e89ab': 'Pierpont,',\n",
       " '57302f5e947a6a140053d24e': 'Samnites,',\n",
       " '5726aad5708984140094cd5d': 'pole.',\n",
       " '5709e9336d058f1900182c19': 'acrobatic.',\n",
       " '572ef802dfa6aa1500f8d4fb': 'alliance,',\n",
       " '5728dac8ff5b5019007da82b': 'Cyclopes,',\n",
       " '57262e04ec44d21400f3dbc0': 'Indonesia,',\n",
       " '570629ba52bb891400689915': 'signal.',\n",
       " '572961606aef051400154dbd': 'happiness.',\n",
       " '56db62cce7c41114004b504f': 'Michael',\n",
       " '5730985d396df919000961ef': 'mathematics.',\n",
       " '570612ce52bb891400689857': 'boom.',\n",
       " '572922ae1d0469140077909b': 'atoms.',\n",
       " '5725c455ec44d21400f3d515': 'Arabic.',\n",
       " '56f8bfd99e9bad19000a0411': 'SURGE,',\n",
       " '56d5afb81c85041400946dc3': 'tails:',\n",
       " '572fa1f9a23a5019007fc7ea': 'sheath',\n",
       " '56dc5f8a14d3a41400c2682b': 'size.',\n",
       " '56df5a5d96943c1400a5d407': 'Streeter',\n",
       " '5725b55d38643c19005acb9f': 'billion,',\n",
       " '56f8f3eb9e9bad19000a076d': '1916,',\n",
       " '572a332b1d0469140077983e': 'Ottoman',\n",
       " '5729225a1d04691400779093': '\"caution',\n",
       " '5724eebf0ba9f01400d97bc8': 'Melbourne,',\n",
       " '5728367e4b864d1900164750': '1913,',\n",
       " '57302668947a6a140053d190': 'Boot\"',\n",
       " '56de9b07cffd8e1900b4ba2b': 'BC)',\n",
       " '57268a1a708984140094c945': 'first,',\n",
       " '5726acd3708984140094cd93': 'Romanesque',\n",
       " '5725b40389a1e219009abd0a': 'Corsica',\n",
       " '56cff3f4234ae51400d9c153': '21',\n",
       " '56faed40f34c681400b0c1b3': 'Somali',\n",
       " '57286e382ca10214002da33e': 'omnipotent.',\n",
       " '5729f6b13f37b31900478618': 'energy,',\n",
       " '572fcebd04bcaa1900d76d71': 'canceled—even',\n",
       " '5706d7150eeca41400aa0e6b': 'Theoretical',\n",
       " '572e81f2cb0c0d14000f1207': 'Wars.',\n",
       " '5726c9505951b619008f7e0f': 'accuracy,',\n",
       " '57260903ec44d21400f3d815': 'Korea',\n",
       " '5726f818f1498d1400e8f153': 'Bonita\".',\n",
       " '57276fdcdd62a815002e9cdc': 'routes,',\n",
       " '5726767edd62a815002e85d9': 'transmitted)',\n",
       " '56f88e06aef2371900626180': 'traits.',\n",
       " '5726e1f45951b619008f8155': 'butterflies.',\n",
       " '56cf3862aab44d1400b88e8e': 'South',\n",
       " '5725b4ef38643c19005acb95': 'Judeans',\n",
       " '57338653d058e614000b5c81': '1879,',\n",
       " '573242f1b9d445190005e93e': 'century,',\n",
       " '572fc108947a6a140053cc49': '1992',\n",
       " '572994ff1d0469140077955f': 'Charles',\n",
       " '570d8ff5b3d812140066da34': 'mm,',\n",
       " '570c9615fed7b91900d45a06': 'Nou,',\n",
       " '56fa1ee4f34c681400b0bfbd': 'ring-porous',\n",
       " '5731cc95e99e3014001e62ae': 'them.\"',\n",
       " '56e145b6e3433e1400422d28': '10%',\n",
       " '570ddac40dc6ce1900204cc4': '73%',\n",
       " '572bd9a9dfb02c14005c6ae0': 'James',\n",
       " '56e887cd99e8941900975e6a': '1902,',\n",
       " '5727e9773acd2414000defa1': '30',\n",
       " '56db1cbee7c41114004b4d5e': 'speech\"',\n",
       " '572baafbf75d5e190021fe93': 'thirty',\n",
       " '572ca85f750c471900ed4cc1': 'Patrol',\n",
       " '5726d4dfdd62a815002e919d': 'philosophy',\n",
       " '56f8d1ba9b226e1400dd1079': 'polymorphic.',\n",
       " '56e8862699e8941900975e57': 'Site.',\n",
       " '573123ff05b4da19006bcded': 'vasodilation',\n",
       " '570e43e60dc6ce1900204ef5': '75%',\n",
       " '56e067a27aa994140058e454': '(Southeast),',\n",
       " '5726b8c8dd62a815002e8e33': '127,000',\n",
       " '570a0f9d4103511400d59548': 'Arminia',\n",
       " '56e7989c37bdd419002c41d3': '1949,',\n",
       " '5727972a708984140094e1a8': 'Brazil,',\n",
       " '57305fc38ab72b1400f9c4b4': 'artist.',\n",
       " '5726b36add62a815002e8d54': 'Hardgrave.',\n",
       " '5709720ded30961900e84162': 'juice',\n",
       " '56df5a5d96943c1400a5d406': 'Kingdom,',\n",
       " '57071a0c90286e26004fc901': 'Madero.',\n",
       " '572808852ca10214002d9c09': 'symptoms,',\n",
       " '5728f603af94a219006a9e75': '1889.',\n",
       " '56dcfc1f66d3e219004dab76': '10',\n",
       " '56f9849c9e9bad19000a0a01': 'prominence—particularly',\n",
       " '571a9f6a4faf5e1900b8ab42': 'appointees,',\n",
       " '57277b69dd62a815002e9e29': 'nail',\n",
       " '572b4c90111d821400f38e37': '1695,',\n",
       " '57277b12708984140094dece': '1880s',\n",
       " '570c0dc5ec8fbc190045bc3d': '2000.',\n",
       " '5729939d1d04691400779554': 'Directoire',\n",
       " '5708085c9e06ca38007e951e': 'deputy.',\n",
       " '5728b30aff5b5019007da4cc': 'Oldfield',\n",
       " '56d10be817492d1400aab803': 'Hawaii',\n",
       " '56e8272b37bdd419002c447d': 'dialects',\n",
       " '572f82f1947a6a140053c9f3': '4,500',\n",
       " '56cfdf65234ae51400d9bfcd': 'outputs.',\n",
       " '57299b841d04691400779579': 'Quinlan',\n",
       " '56e7b06e37bdd419002c435c': 'League.',\n",
       " '572852073acd2414000df905': '1929–1930.',\n",
       " '56fae2fc8f12f3190063023d': 'Mogadishu,',\n",
       " '5727f9a33acd2414000df131': 'gravity.',\n",
       " '573402d3d058e614000b67a4': 'units.',\n",
       " '5726ad33708984140094cd9c': 'Avon',\n",
       " '56e1657ee3433e1400422e80': '360-acre',\n",
       " '5731b46ee99e3014001e61e6': 'right,',\n",
       " '570c6526b3d812140066d1d1': 'Carta,',\n",
       " '572a353c3f37b319004787b2': 'Doones\".',\n",
       " '57301d28b2c2fd14005688ad': 'Calpurnius',\n",
       " '5726ddf15951b619008f809b': 'di-dèguè',\n",
       " '57325fade17f3d14004228fc': 'Dodge,',\n",
       " '56d660e91c850414009470d5': 'China,',\n",
       " '56e7882837bdd419002c40cc': '(SAUD)',\n",
       " '5727cf404b864d1900163da0': 'Queen',\n",
       " '5726ffac5951b619008f8451': 'zone;',\n",
       " '5732bcead6dcfa19001e8a99': '\"less-lethal\")',\n",
       " '57340cf1d058e614000b689d': 'also,',\n",
       " '570d6de5fed7b91900d460b8': '1519–1523',\n",
       " '572848bc3acd2414000df881': 'Serbo-Croatian',\n",
       " '573420e34776f419006618ee': '2007,',\n",
       " '57262d01ec44d21400f3dba7': '(LNG)',\n",
       " '5726cd44dd62a815002e90ac': 'Emilio',\n",
       " '56ce81bdaab44d1400b88817': 'output.',\n",
       " '56e14e04cd28a01900c6777c': 'Boston',\n",
       " '5706195175f01819005e797a': '1883,',\n",
       " '56e16c1ae3433e1400422efe': '1914,',\n",
       " '5731b690b9d445190005e49e': '\"Now',\n",
       " '56e6de276fe0821900b8ec0a': '\"mass\"',\n",
       " '570aa5244103511400d598c4': 'Vladivostok.',\n",
       " '5726431a38643c19005ad3c4': 'rule,',\n",
       " '57277ee9f1498d1400e8f9d1': '\"Pencil',\n",
       " '5728b2813acd2414000dfcf8': 'century,',\n",
       " '572ec0e903f98919007569f8': 'Arabic,',\n",
       " '572bf75fdfb02c14005c6b10': 'God',\n",
       " '56bec9f13aeaaa14008c9469': 'Mendler,',\n",
       " '56d3665c59d6e414001462e1': 'Jackson,',\n",
       " '57325b14e17f3d14004228db': 'boroughs,',\n",
       " '56e16c1ae3433e1400422efd': 'Zeppelins;',\n",
       " '56e180f5e3433e1400422f96': '95%.',\n",
       " '5726d6d8708984140094d2f8': 'judiciary.',\n",
       " '5726696b708984140094c522': 'acids.',\n",
       " '5732aa5bcc179a14009dabdd': 'by:',\n",
       " '56f92c0f9e9bad19000a07f1': 'Cooper',\n",
       " '572997743f37b319004784c8': 'Štokavian',\n",
       " '56dfe9737aa994140058e265': 'versions)',\n",
       " '56f736e2711bf01900a44a6e': 'Czechoslovakia',\n",
       " '56de3e40cffd8e1900b4b6df': 'President',\n",
       " '5728e9944b864d190016507f': 'myths,',\n",
       " '572ed3f503f9891900756a67': 'Levantines',\n",
       " '572fedf6947a6a140053ce1c': 'Basra,',\n",
       " '572ee20bdfa6aa1500f8d492': 'treason.',\n",
       " '57345be2879d6814001ca558': 'Chesterfield',\n",
       " '5727e9b23acd2414000defb5': 'traditions;',\n",
       " '573089b78ab72b1400f9c560': 'Scandinavians,',\n",
       " '5727ea07ff5b5019007d9863': 'Hotel',\n",
       " '56e13873cd28a01900c676c9': '1934,',\n",
       " '5730376e04bcaa1900d77398': 'states.',\n",
       " '57099056ed30961900e8432c': '1963,',\n",
       " '5727eb332ca10214002d99b0': '1661',\n",
       " '572ecc82c246551400ce46a8': 'Motornoye,',\n",
       " '570d1d42b3d812140066d425': 'Tagalog',\n",
       " '572912746aef051400154a28': '\"culture\",',\n",
       " '5728d449ff5b5019007da7a0': 'London',\n",
       " '572b5334111d821400f38e64': 'similarity.',\n",
       " '57281407ff5b5019007d9ca7': 'isomorphic',\n",
       " '572940ea6aef051400154bf6': 'Hamden.',\n",
       " '56e6de2cde9d3714000680b5': 'Generation',\n",
       " '57342f81d058e614000b6abb': 'exist,',\n",
       " '572ee58003f9891900756ad5': 'China,',\n",
       " '5731beafe17f3d1400422372': 'Christocentric.',\n",
       " '5733d5f24776f41900661314': '1945.',\n",
       " '56f8b1c99e9bad19000a0343': '21-storey',\n",
       " '57262af9ec44d21400f3db85': 'terrorism',\n",
       " '5705ef1452bb8914006896e9': 'Pliny',\n",
       " '572f1f9004bcaa1900d7675b': 'spinning,',\n",
       " '57313756a5e9cc1400cdbd09': 'BC',\n",
       " '572684db5951b619008f7551': 'Kingman',\n",
       " '5727311af1498d1400e8f460': '1479',\n",
       " '57313b9a497a881900248ca4': '2015,',\n",
       " '5730df7eaca1c71400fe5b21': '15,000',\n",
       " '5729d6d76aef0514001550b2': 'chips',\n",
       " '57281c7f4b864d19001644ac': 'Italy,',\n",
       " '57324ffa0fdd8d15006c695f': 'five',\n",
       " '57317b65e6313a140071cf92': '2003,',\n",
       " '570688d052bb891400689a4f': 'sleep.',\n",
       " '572a7a17be1ee31400cb8029': 'Group,',\n",
       " '5733dd1d4776f419006613a5': 'Zerafshan',\n",
       " '571de5e2556973190063909c': 'multiracial.',\n",
       " '5727d6363acd2414000dedc2': 'Confucianism,',\n",
       " '572e6ada03f9891900756689': 'controversy.',\n",
       " '573254dab9d445190005ea45': '37%',\n",
       " '572ab2abf75d5e190021fc4d': 'Mantar,',\n",
       " '57325e6d0fdd8d15006c6a41': 'BeDuhn,',\n",
       " '57260512271a42140099d3d0': '49',\n",
       " '5731c904b9d445190005e551': 'antibacterial',\n",
       " '572a6389d562191400bc86ab': 'capital,',\n",
       " '572f435f947a6a140053c82b': 'million',\n",
       " '56f75e62aef2371900625b6b': 'law.',\n",
       " '57340cf1d058e614000b689e': '1917.',\n",
       " '57317c2b497a881900248f7c': '1976,',\n",
       " '57266312f1498d1400e8ddda': 'City,',\n",
       " '570ff84db654c5140001f705': 'traditional',\n",
       " '56d10a4717492d1400aab7d8': 'electric',\n",
       " '57267966708984140094c74b': 'Wight.',\n",
       " '56dc575814d3a41400c267e1': 'Fiers',\n",
       " '57344892879d6814001ca481': 'Actaeon,',\n",
       " '5727a4574b864d1900163925': 'anonymity.',\n",
       " '5728de4d2ca10214002da9e6': 'Systems',\n",
       " '57270d33dd62a815002e985d': '25%',\n",
       " '571a72d84faf5e1900b8a9b4': 'striatum,',\n",
       " '572ab1b4f75d5e190021fc42': 'May',\n",
       " '56df206e3277331400b4d98e': 'Woodhead',\n",
       " '57270c73f1498d1400e8f29f': '100%.',\n",
       " '56d5da871c85041400946e37': 'humans.',\n",
       " '57267ed25951b619008f74a8': 'A9.',\n",
       " '5724d6a60ba9f01400d97b94': 'Maclean,',\n",
       " '570e70c30b85d914000d7eff': 'Victoria',\n",
       " '56cd5ccc62d2951400fa6536': 'suzerainty.\"',\n",
       " '5730956e396df919000961c5': 'experiential,',\n",
       " '56e0a38a231d4119001ac303': 'Ivangorod',\n",
       " '5727be744b864d1900163c50': 'Richard',\n",
       " '5727b8b3ff5b5019007d936c': 'cells,',\n",
       " '570e6e890b85d914000d7ee9': 'Krishnadevaraya',\n",
       " '572eb23f03f9891900756972': 'eschatology',\n",
       " '570e357f0b85d914000d7d69': 'solution.',\n",
       " '56dfb89e7aa994140058e06f': 'inns,',\n",
       " '5725d9a889a1e219009abfb2': 'Rimer',\n",
       " '57302f95b2c2fd1400568a1c': '(Ground',\n",
       " '572519c80a492a19004356f8': 'million',\n",
       " '57307b852461fd1900a9ce50': \"Macpherson's\",\n",
       " '57286e382ca10214002da33d': 'omnipotent.',\n",
       " '572a36fe3f37b319004787c6': 'Russia.',\n",
       " '57302b8004bcaa1900d772bb': 'Russell',\n",
       " '5731239605b4da19006bcde8': 'power.',\n",
       " '56f73db4aef2371900625a41': 'Pact,',\n",
       " '5724e5bd0ba9f01400d97baa': 'Albert',\n",
       " '56d2429fb329da140004ec93': 'vipassanā',\n",
       " '57269c5f5951b619008f77bf': 'Alexei',\n",
       " '56f959be9b226e1400dd1380': '1904',\n",
       " '56cd8a5f62d2951400fa668e': 'Purinsesu?)',\n",
       " '5728cf512ca10214002da863': 'effective.',\n",
       " '5733e19dd058e614000b64ad': '36,000,',\n",
       " '570b44876b8089140040f846': '1943–45,',\n",
       " '57282af73acd2414000df5ff': 'semi-sessile',\n",
       " '5728200fff5b5019007d9d96': '1682',\n",
       " '5727c4324b864d1900163cc4': 'percussion,',\n",
       " '5726925ef1498d1400e8e425': '\"vreemdeling\".',\n",
       " '573234a9e17f3d1400422722': 'Echmiadzin.',\n",
       " '56df98d938dc4217001520b8': 'Bell,',\n",
       " '5727a8874b864d19001639b8': 'nine',\n",
       " '572778755951b619008f8abb': '1857,',\n",
       " '5727891b708984140094e034': 'confrontation.',\n",
       " '5726c67d708984140094d12d': 'nonviolent',\n",
       " '56daf672e7c41114004b4bb8': 'million',\n",
       " '56defc4bc65bf219000b3e87': 'operations.',\n",
       " '56d4c4e72ccc5a1400d8321b': 'Blue',\n",
       " '56f7f695aef2371900625cfe': 'Uprising.',\n",
       " '572677855951b619008f738e': 'compression),',\n",
       " '5730435ab2c2fd1400568b20': 'antenna.',\n",
       " '56e7a2d137bdd419002c42ac': 'minting,',\n",
       " '5727b47d2ca10214002d945a': 'vinegar-and-red-pepper-based',\n",
       " '572674b8f1498d1400e8e034': 'Gore,',\n",
       " '56df81eb5ca0a614008f9bbf': '1596',\n",
       " '572e7ff1cb0c0d14000f11d5': 'Serber.',\n",
       " '56dff0b1231d4119001abed4': \"Blair's\",\n",
       " '56d9e5a0dc89441400fdb8c0': 'routines',\n",
       " '573426c64776f41900661989': 'Discovery.',\n",
       " '571aa5ad10f8ca1400305251': '720.',\n",
       " '57336480d058e614000b59fe': '(Jan.',\n",
       " '5726b9ba708984140094cf45': 'Pharo,',\n",
       " '570624bb52bb8914006898ef': '\"Inlet\"',\n",
       " '572fc3d204bcaa1900d76cad': 'Thailand.',\n",
       " '5706117a75f01819005e7935': '(TLS)',\n",
       " '57080a949928a814004714b6': 'al-Sadiq.',\n",
       " '570d7be1b3d812140066d9e2': 'Gambetta',\n",
       " '571035f5a58dae1900cd6974': 'sexual-orientation',\n",
       " '5726dc90dd62a815002e931a': 'pinyin',\n",
       " '5727e4a64b864d1900163f71': 'Spring',\n",
       " '5727e0603acd2414000deeb9': 'earth.',\n",
       " '572a8395111d821400f38b91': 'two',\n",
       " '56f81fe6aef2371900625df8': 'ibex',\n",
       " '572847713acd2414000df865': 'algorithm,',\n",
       " '572a2927af94a219006aa84a': '7',\n",
       " '570d2cb4fed7b91900d45cb5': 'Jobs,',\n",
       " '5728062d3acd2414000df283': 'algebraic',\n",
       " '5726733b5951b619008f72f1': 'Finlay',\n",
       " '56f730303d8e2e1400e37416': \"'self-executing',\",\n",
       " '56d11b8d17492d1400aab997': 'Atticus',\n",
       " '56dece3bc65bf219000b3d41': 'I,',\n",
       " '572f68b3a23a5019007fc5e1': '$16.98.',\n",
       " '57273572dd62a815002e9991': 'Herbert',\n",
       " '57277cf8708984140094deff': 'cultures.',\n",
       " '57266a39dd62a815002e842e': 'Gustafson;',\n",
       " '5724eebf0ba9f01400d97bc9': '28',\n",
       " '570cef82b3d812140066d340': 'acid',\n",
       " '572785ddf1498d1400e8fabe': 'Moixo',\n",
       " '573245f7b9d445190005e97f': '240',\n",
       " '5726715df1498d1400e8dfd0': '1,200',\n",
       " '572a5df77a1753140016aee1': '1860,',\n",
       " '57343e3a4776f41900661aed': '2.6%',\n",
       " '57295a761d04691400779302': 'Leverock.',\n",
       " '5723df250dadf01500fa1f59': '1858,',\n",
       " '572e8e84dfa6aa1500f8d121': 'resumed,',\n",
       " '5727842bdd62a815002e9f52': 'Murray,',\n",
       " '570a3a0e6d058f1900182d02': '1516,',\n",
       " '5730083f04bcaa1900d77040': 'Azerbaijan,',\n",
       " '5731d14ee99e3014001e62ec': '2006,',\n",
       " '570e53690b85d914000d7e3b': 'housing.',\n",
       " '5732a92f328d981900601ff6': 'Brazil,',\n",
       " '573118d705b4da19006bcd9a': 'Anseriformes',\n",
       " '56d0e08817492d1400aab66e': 'Vajrayana,',\n",
       " '57305a8e396df9190009609d': 'London.',\n",
       " '5727eda1ff5b5019007d98bd': 'Cairo',\n",
       " '5725baec38643c19005acbf5': '1970s,',\n",
       " '572651775951b619008f6fc1': '\"George,',\n",
       " '56d3760759d6e41400146474': 'Doolittle',\n",
       " '5734284ad058e614000b6a48': 'PCR',\n",
       " '56cda10262d2951400fa6795': 'Minegishi',\n",
       " '5727f4004b864d190016408a': 'Oresme',\n",
       " '572fadc5947a6a140053cb61': 'Washington',\n",
       " '56db1cbee7c41114004b4d5f': 'Birkin,',\n",
       " '56eaaa8f5a205f1900d6d3d8': 'Manuel',\n",
       " '5731d666e17f3d1400422487': '17,000',\n",
       " '570d3cf6fed7b91900d45d70': '$250',\n",
       " '572f62ff947a6a140053c90b': '980,263',\n",
       " '572910176aef051400154a10': 'conditions.',\n",
       " '5726a7ef708984140094cd09': 'Day.',\n",
       " '56f7fd15a6d7ea1400e17362': 'Virgil,',\n",
       " '56d8a84abfea0914004b7719': 'Rogge',\n",
       " '57302b2ab2c2fd14005689c8': 'passwords),',\n",
       " '570e38fd0b85d914000d7d96': 'Harar',\n",
       " '5729319b3f37b319004780dc': 'John',\n",
       " '5726b49d708984140094ce6c': 'Coe',\n",
       " '572a2cfc1d0469140077981a': 'Pasha,',\n",
       " '56dc5de314d3a41400c2681f': 'Genome',\n",
       " '56df11aac65bf219000b3f1f': '1954',\n",
       " '57280a4fff5b5019007d9b99': '1907,',\n",
       " '56e6ebc66fe0821900b8ec2f': '28',\n",
       " '572616c289a1e219009ac235': 'Stadium,',\n",
       " '56df740d56340a1900b29ba4': 'million',\n",
       " '5724f8f90a492a190043569a': 'proclamation.',\n",
       " '56de4529cffd8e1900b4b75e': 'seven',\n",
       " '57269289dd62a815002e89fe': 'Yale,',\n",
       " '57265854f1498d1400e8dca5': 'Cuba,',\n",
       " '56e141e2e3433e1400422d06': '15.8%',\n",
       " '572ff126947a6a140053ce40': '(1213–1288),',\n",
       " '57302bd0a23a5019007fceef': '1929.',\n",
       " '56df60fc8bc80c19004e4b65': 'scandal,',\n",
       " '573444a1879d6814001ca43e': 'Lowe,',\n",
       " '57269c73708984140094cbb7': 'ummah,',\n",
       " '56cd937162d2951400fa6732': 'magic.',\n",
       " '572e7d44dfa6aa1500f8d02c': 'radios.',\n",
       " '570d3164fed7b91900d45cf1': 'slots,',\n",
       " '570c4d68b3d812140066d0a3': 'Lowe,',\n",
       " '5733f93e4776f41900661603': 'Minister.',\n",
       " '5727af682ca10214002d93bc': 'House,',\n",
       " '56cf3aa2aab44d1400b88ec1': 'Prosperity',\n",
       " '5726f50add62a815002e9634': 'India,',\n",
       " '56f82341aef2371900625e13': 'Slovenia.',\n",
       " '56db059de7c41114004b4c59': '10–)',\n",
       " '5731bcb1b9d445190005e4e7': '32,000',\n",
       " '57097780200fba1400368035': 'researched.',\n",
       " '5727b78d4b864d1900163b34': '1,400.',\n",
       " '5728d0683acd2414000dff31': 'Paris',\n",
       " '56e15fabcd28a01900c6782b': 'Boston',\n",
       " '5725fbcbec44d21400f3d7c4': 'Rome.',\n",
       " '56f7227a711bf01900a449c5': '\"palette\"',\n",
       " '57100c2ea58dae1900cd6809': 'techniques.',\n",
       " '572a992cf75d5e190021fb7a': 'Charles',\n",
       " '56d650911c850414009470a0': 'Parents',\n",
       " '56ce345caab44d1400b88584': '\"Nouvelle',\n",
       " '572fa576b2c2fd140056829b': 'bodies,',\n",
       " '57267681708984140094c70b': 'final-obstruent',\n",
       " '5727876f5951b619008f8c7d': 'three,',\n",
       " '5726acb05951b619008f79b3': 'Al-Qaeda.\"',\n",
       " '5728e0eb2ca10214002daa10': 'Asia.',\n",
       " '572a3b543f37b319004787f2': 'crust.',\n",
       " '56e0cc407aa994140058e712': 'Safari',\n",
       " '57268d7ef1498d1400e8e396': 'billion,',\n",
       " '56f72c443d8e2e1400e373cd': 'Billy',\n",
       " '572688fd708984140094c92c': '\"Take',\n",
       " '56cfba85234ae51400d9bf16': '4:',\n",
       " '5731e04ce17f3d14004224e5': '28.7%,',\n",
       " '56de65324396321400ee2883': \"Plymouth's\",\n",
       " '5726e48ff1498d1400e8ef04': 'Animal',\n",
       " '56dee1f8c65bf219000b3dc7': 'logistics,',\n",
       " '56e79deb37bdd419002c424c': '$100',\n",
       " '5727ad322ca10214002d936c': 'Ba-Shu',\n",
       " '56de15cd4396321400ee25bf': 'three',\n",
       " '5730ff8ba5e9cc1400cdbb81': '(Services)',\n",
       " '570a811e4103511400d597a0': 'University,',\n",
       " '570bfb6dec8fbc190045bbf7': 'systems.',\n",
       " '57266dcf5951b619008f7279': 'Alexander,',\n",
       " '56eaaa8f5a205f1900d6d3d6': 'Manuel',\n",
       " '56cf49d7aab44d1400b88f46': '19,000',\n",
       " '571a8b9d4faf5e1900b8aa5b': 'Father.',\n",
       " '5726b702f1498d1400e8e8a6': 'months,',\n",
       " '572ff0a2947a6a140053ce39': '19',\n",
       " '5706300775f01819005e7a61': '(compressed)',\n",
       " '5730a5e02461fd1900a9cf3e': 'Kombat,',\n",
       " '56f7ff5faef2371900625d55': '(25',\n",
       " '572fcd1004bcaa1900d76d52': 'Japan.',\n",
       " '57310e01497a881900248b53': '50%',\n",
       " '56fa3d788f12f319006300ff': 'radial',\n",
       " '56e11e2fcd28a01900c675fb': '2007.',\n",
       " '56e1483acd28a01900c67733': 'moguls,',\n",
       " '57283f6d2ca10214002da17a': 'Groupoids',\n",
       " '572fabfe947a6a140053cb4e': 'database.',\n",
       " '572a2fefaf94a219006aa873': 'Yale',\n",
       " '570a718e4103511400d5971e': 'Vetter',\n",
       " '57273cb5dd62a815002e99e8': 'gin',\n",
       " '573263c6e17f3d1400422949': 'safety.',\n",
       " '57344a5b879d6814001ca4ae': 'century,',\n",
       " '5707233f90286e26004fc951': 'Durango,',\n",
       " '573420d9d058e614000b6998': 'benign.',\n",
       " '56bfaa11a10cfb1400551217': '300',\n",
       " '5728fd971d04691400778f28': 'rules.',\n",
       " '5705f31c52bb891400689710': '1797)',\n",
       " '56e79deb37bdd419002c424a': 'Benson',\n",
       " '571aae454faf5e1900b8ac0f': 'I,',\n",
       " '5732452ee99e3014001e6603': 'earnest,',\n",
       " '57265ece708984140094c3db': 'hall,',\n",
       " '572fc3b7a23a5019007fc9ba': 'Aivali,',\n",
       " '5730ea0fb7151e1900c015c8': 'longer,',\n",
       " '56df860a56340a1900b29ce3': '30',\n",
       " '56e07c3b231d4119001ac1c8': 'Lancaster',\n",
       " '5729649b6aef051400154def': 'vacant.',\n",
       " '56ce7c26aab44d1400b887fb': '1979',\n",
       " '5725e5ce38643c19005ace53': 'France.',\n",
       " '56e14e56cd28a01900c67787': 'Technicolor',\n",
       " '5729442b3f37b319004781dc': 'resources.',\n",
       " '5733ecdb4776f41900661521': 'Silva.',\n",
       " '572fea66b2c2fd14005685d2': '3f0',\n",
       " '572675ae5951b619008f7341': 'Lou',\n",
       " '572832643acd2414000df6c5': \"Arafat's\",\n",
       " '56d37afb59d6e414001464df': 'DioGuardi.',\n",
       " '573014f1a23a5019007fcd2e': '1862,',\n",
       " '5729f6b13f37b3190047861a': 'energy,',\n",
       " '5727a4ee3acd2414000de8b8': 'death.',\n",
       " '56db2c98e7c41114004b4eb3': '–',\n",
       " '5731a97bb9d445190005e439': 'aura',\n",
       " '56f8b1c99e9bad19000a0341': 'economy',\n",
       " '56e070687aa994140058e4c3': 'Western',\n",
       " '5726b1c0708984140094ce10': 'twenty',\n",
       " '570c3ff26b8089140040fc64': 'million',\n",
       " '5709f21e4103511400d594b3': 'I,',\n",
       " '570a842b6d058f1900182f0c': '⟨ƿ⟩,',\n",
       " '573027ba04bcaa1900d77261': 'constitution',\n",
       " '56d3831159d6e414001465d2': 'Fradiani',\n",
       " '5727785fdd62a815002e9dc2': 'abolished.',\n",
       " '572a3cf63f37b3190047880c': 'Yale',\n",
       " '5726cded5951b619008f7e85': '50',\n",
       " '5719da2d4faf5e1900b8a82a': 'grunge,',\n",
       " '57271739f1498d1400e8f387': 'exercise,',\n",
       " '5733e009d058e614000b648a': 'societies.',\n",
       " '57336f3ed058e614000b5b09': 'Blanc.',\n",
       " '5731388ea5e9cc1400cdbd2a': 'Theo',\n",
       " '57278fa6708984140094e0e6': 'William',\n",
       " '572950423f37b3190047822e': 'Unions.',\n",
       " '56e0ea497aa994140058e7b2': 'Korolev',\n",
       " '56d347fb59d6e4140014629f': '3',\n",
       " '570a5f946d058f1900182dd8': 'Felix,',\n",
       " '56e1944ae3433e1400422fdf': 'Lyman-alpha',\n",
       " '5726fa88708984140094d785': 'Sevastopol,',\n",
       " '5726be91dd62a815002e8f2e': 'Faleiva',\n",
       " '57101cc5a58dae1900cd689f': 'interviews,',\n",
       " '572ebc97dfa6aa1500f8d334': 'Brown,',\n",
       " '5730fa4b05b4da19006bccb1': 'devices.',\n",
       " '5731edafe17f3d140042255c': 'Smyth',\n",
       " '56e8e8bf0b45c0140094cd57': 'London',\n",
       " '56cc08eb6d243a140015ee70': 'piano,',\n",
       " '56df73c156340a1900b29b99': '1992',\n",
       " '5733ce494776f41900661298': '1951',\n",
       " '57342d2b4776f41900661a0e': 'infection',\n",
       " '5706347875f01819005e7a90': 'Decoding,',\n",
       " '572929766aef051400154b00': 'Physics',\n",
       " '57282d253acd2414000df65b': 'Union.',\n",
       " '572a44ec6aef0514001553f4': 'models,',\n",
       " '570fc66e5ab6b81900390fb5': 'December',\n",
       " '56d39cea59d6e41400146814': 'Schumann',\n",
       " '572982021d046914007794ef': 'quenching.',\n",
       " '56d3895c59d6e4140014669e': '120',\n",
       " '56f89fc39b226e1400dd0ced': 'complementary,',\n",
       " '5733c432d058e614000b61f8': 'Nacional',\n",
       " '572b6eeb34ae481900deae0d': 'Arthur',\n",
       " '5726c717dd62a815002e9000': 'thirty',\n",
       " '572805ad2ca10214002d9bc3': \"Year'.\",\n",
       " '5728cf512ca10214002da864': 'Organization.',\n",
       " '570ce4c0b3d812140066d2f6': 'RAM,',\n",
       " '5730807e069b53140083212b': 'accuracy,',\n",
       " '56f7f364a6d7ea1400e1730b': 'Yugoslavia',\n",
       " '572716baf1498d1400e8f380': 'Wheeler,',\n",
       " '5729734f6aef051400154efd': 'subsidies,',\n",
       " '56d36db659d6e4140014637a': 'eight',\n",
       " '571ae6b632177014007e9fbe': '27',\n",
       " '56d1f2b4e7d4791d009025b0': 'Buddha',\n",
       " '57310d75497a881900248b49': 'Moustakas',\n",
       " '572aac99111d821400f38ca1': 'Rajasthan',\n",
       " '572997463f37b319004784bf': 'size.',\n",
       " '57098d1bed30961900e842e1': 'oxides:',\n",
       " '5726b9d05951b619008f7beb': 'energy,',\n",
       " '57267681708984140094c70a': 'final-obstruent',\n",
       " '57267609f1498d1400e8e063': '1921',\n",
       " '5732b7fbcc179a14009dac2a': '1968',\n",
       " '572a56c37a1753140016aec4': '62.5%',\n",
       " '56e8f9f90b45c0140094cdb0': '1050',\n",
       " '572fdefc04bcaa1900d76e15': '2011.',\n",
       " '57276815dd62a815002e9c5b': '73%',\n",
       " '56fae60d8f12f31900630271': 'pottery,',\n",
       " '572fc0d2a23a5019007fc97d': 'diffusion',\n",
       " '5709535eefce8f15003a7df6': 'News)',\n",
       " '571a99af4faf5e1900b8ab15': '30',\n",
       " '5730a771069b53140083220d': 'three',\n",
       " '56eaa11d0030b61400a34ff4': 'bribery',\n",
       " '572fbb02b2c2fd14005683ba': 'rife,',\n",
       " '56fdf33b19033b140034cdf6': 'Hopper,',\n",
       " '57318515a5e9cc1400cdc019': 'allies,',\n",
       " '5730564b069b53140083207d': 'Latin,',\n",
       " '572811cc2ca10214002d9d24': 'Gorenstein,',\n",
       " '572b951ef75d5e190021fe5f': 'electronic',\n",
       " '5724d4c80ba9f01400d97b87': 'Leopold,',\n",
       " '57301640b2c2fd1400568833': 'Cornelius',\n",
       " '5726f3ccdd62a815002e960f': 'DIGIMON),',\n",
       " '572faa5304bcaa1900d76b96': 'rods.',\n",
       " '5727b6734b864d1900163b12': 'gas',\n",
       " '5728cc524b864d1900164e43': 'asthma.',\n",
       " '5731fa3c0fdd8d15006c66b3': 'MacArthur',\n",
       " '572790d25951b619008f8da5': 'Comparsas',\n",
       " '5706beac0eeca41400aa0df5': '\"Moors\"',\n",
       " '56cc0d816d243a140015ee7c': 'Nohant,',\n",
       " '5727fd58ff5b5019007d9a47': '1925,',\n",
       " '570fd72880d9841400ab36b9': 'eligible.',\n",
       " '5733fee24776f4190066167f': 'century,',\n",
       " '56f739203d8e2e1400e3749c': 'proliferation.',\n",
       " '56ce3406aab44d1400b8856e': 'Yun',\n",
       " '572f5d5eb2c2fd1400568083': 'purposes.',\n",
       " '570d5b15fed7b91900d45f13': 'Prussian',\n",
       " '573135b605b4da19006bcecc': 'century,',\n",
       " '572f6326947a6a140053c915': 'tandem',\n",
       " '5727624e5951b619008f892d': 'innovations,',\n",
       " '57304225947a6a140053d36c': 'online,',\n",
       " '572867304b864d190016499e': 'Spinoza,',\n",
       " '572f15a303f9891900756b88': 'room\"',\n",
       " '57342937d058e614000b6a65': 'chicken,',\n",
       " '5731404f497a881900248cee': 'opium,',\n",
       " '5707130190286e26004fc8b9': 'dollars)',\n",
       " '572678ca5951b619008f73b8': 'Store.',\n",
       " '57266e29dd62a815002e8495': '10%',\n",
       " '572a84d3f75d5e190021fb3b': 'İznik',\n",
       " '572656fbdd62a815002e8206': 'million',\n",
       " '56e6d8836fe0821900b8ebd8': 'BC).',\n",
       " '56e1573fe3433e1400422ddf': 'Gallo-Romance',\n",
       " '56de6bdacffd8e1900b4b89c': 'Parliamentary',\n",
       " '5725d1a6ec44d21400f3d628': 'children.',\n",
       " '572fa37304bcaa1900d76b27': 'high-speed-steel',\n",
       " '572ed03ccb0c0d14000f15d4': '(25–220',\n",
       " '5726c394f1498d1400e8ea91': 'Montparnasse.',\n",
       " '5733ec8ed058e614000b65f3': 'Olduwan',\n",
       " '570983a2200fba14003680f6': 'Einset',\n",
       " '572866543acd2414000df995': 'DNA',\n",
       " '57269d47708984140094cbd0': '1752,',\n",
       " '5730265d04bcaa1900d7723b': 'Parliament',\n",
       " '57268d79dd62a815002e8957': 'Hidalgo.',\n",
       " '56bfd14ba10cfb1400551309': 'Rosen',\n",
       " '573075b12461fd1900a9ce27': '2009,',\n",
       " '572bbb82111d821400f38f63': 'developer)',\n",
       " '56f961049b226e1400dd13e8': 'Iroij,',\n",
       " '5728d9f14b864d1900164f8f': 'it\"),',\n",
       " '5727d96a4b864d1900163e81': 'population.',\n",
       " '5729e2ea6aef0514001550d8': 'energy,',\n",
       " '56f7f171aef2371900625c9e': '22,',\n",
       " '56f840dea6d7ea1400e17512': 'I,',\n",
       " '5727c4ac2ca10214002d95d4': 'religion.',\n",
       " '57098f5ced30961900e84319': 'intermarriage,',\n",
       " '57310d3fe6313a140071cbbd': 'Byzantium',\n",
       " '57290ad81d04691400778fbf': 'Florida,',\n",
       " '570b26c7ec8fbc190045b888': 'chats,',\n",
       " '56d4ebea2ccc5a1400d8335a': '20',\n",
       " '572868002ca10214002da309': 'video.',\n",
       " '5733e37ad058e614000b64d9': 'maps,',\n",
       " '56e797ad00c9c71400d7732a': '1946,',\n",
       " '5706347875f01819005e7a92': 'Decoding,',\n",
       " '571a7ebb10f8ca14003050a8': '8%',\n",
       " '572fba92a23a5019007fc8e3': '\"Spitfire',\n",
       " '5725bd9f271a42140099d101': 'Cleopatra',\n",
       " '570c5530fed7b91900d458cb': 'Innocent',\n",
       " '56de560a4396321400ee281d': 'Semitic',\n",
       " '572a6ea1d562191400bc86d2': 'chief',\n",
       " '5726413f89a1e219009ac60b': 'ceremonies.',\n",
       " '5731993c0fdd8d15006c63d6': 'chancellor,',\n",
       " '572f6a98947a6a140053c932': 'pointers.',\n",
       " '573179c4a5e9cc1400cdbfa5': 'CIDOB',\n",
       " '56db1f11e7c41114004b4d9b': 'expression.',\n",
       " '572fd15da23a5019007fca36': 'renovations.',\n",
       " '57324f18b9d445190005ea1b': 'five',\n",
       " '572eae27cb0c0d14000f1453': 'smoked,',\n",
       " '572827192ca10214002d9f54': 'fibers,',\n",
       " '570d53f9b3d812140066d6c5': '1460',\n",
       " '57276669f1498d1400e8f76e': 'feasting,',\n",
       " '5726ca95f1498d1400e8eb56': 'canalized;',\n",
       " '573402084776f419006616ba': 'foods.',\n",
       " '56df53138bc80c19004e4a91': 'Lightolier,',\n",
       " '56d089e6234ae51400d9c360': '1974,',\n",
       " '572a21741d046914007797c5': 'inertia',\n",
       " '57329fe2cc179a14009dab87': 'oppression\"',\n",
       " '56f990bd9b226e1400dd15a4': '2009,',\n",
       " '572f20af04bcaa1900d76763': 'Thomas',\n",
       " '5706962d52bb891400689aaf': 'Soul',\n",
       " '56d0fc6417492d1400aab6ee': 'pain.',\n",
       " '56de05334396321400ee2554': 'Aramaic-derived',\n",
       " '5726ecae708984140094d63c': 'Codes,',\n",
       " '5731b8a4e17f3d140042231d': 'bull:',\n",
       " '56e7a4c900c9c71400d77474': 'November',\n",
       " '57265a1ef1498d1400e8dce6': '1',\n",
       " '56e03c7e231d4119001ac00d': 'onomatopoeia',\n",
       " '5726cbd25951b619008f7e57': 'union.',\n",
       " '5727a440ff5b5019007d91bb': 'work.',\n",
       " '5706b11d0eeca41400aa0d35': 'Manchester,',\n",
       " '5726dea3f1498d1400e8ee1a': 'master,',\n",
       " '56e0a41f7aa994140058e68c': 'East',\n",
       " '5734291d4776f419006619d7': 'Giffords,',\n",
       " '570e59e00b85d914000d7e65': 'Sanskrit',\n",
       " '572f8b9b947a6a140053ca4f': 'Charminar,',\n",
       " '572661dedd62a815002e833a': 'Starfish',\n",
       " '56e8e8bf0b45c0140094cd59': 'Louis',\n",
       " '57280b503acd2414000df307': 'English;',\n",
       " '570fa86a5ab6b81900390f79': 'heterosexual',\n",
       " '56e1b738cd28a01900c67aad': 'Valencian',\n",
       " '56d39c5359d6e4140014680e': 'playing—for',\n",
       " '56db3f2ce7c41114004b4f9d': 'white',\n",
       " '56cd480b62d2951400fa650f': 'Professor',\n",
       " '573427834776f4190066199f': 'road,',\n",
       " '5726cfe5708984140094d213': 'hydration.',\n",
       " '57268e98708984140094c9ff': 'intervened.',\n",
       " '573148a7497a881900248d4e': '30%',\n",
       " '5728d0114b864d1900164ea2': '1925',\n",
       " '5726d39add62a815002e9196': 'Józef',\n",
       " '5726f3eef1498d1400e8f0ca': 'theorem',\n",
       " '570cdfbefed7b91900d45a4d': '2011,',\n",
       " '57340d8cd058e614000b68a8': 'Community,',\n",
       " '57321ccfb9d445190005e811': 'Caesar,',\n",
       " '56f8e22c9e9bad19000a0685': 'Anatolia',\n",
       " '56f98f329b226e1400dd1574': 'axon.',\n",
       " '56dfc5897aa994140058e18f': 'pine',\n",
       " '56dcdbe566d3e219004dab37': 'Pygmy',\n",
       " '572e7d5203f98919007566af': 'Amistad),',\n",
       " '56cd937162d2951400fa6734': 'magic.',\n",
       " '571b3f7632177014007ea048': 'Alberta,',\n",
       " '56df1fcec65bf219000b3f70': 'Music,',\n",
       " '5731bbe8e17f3d1400422343': 'raising,',\n",
       " '5728ec9d2ca10214002daaa2': 'Governors,',\n",
       " '56dafa15e7c41114004b4bf5': 'cancelled.',\n",
       " '573086f82461fd1900a9ce81': 'concourses,',\n",
       " '56dfe86b7aa994140058e252': 'III,',\n",
       " '5730f84ce6313a140071cb18': 'Caprivi.',\n",
       " '56f8d10e9b226e1400dd1066': '(National',\n",
       " '572649565951b619008f6f17': 'Arnold,',\n",
       " '57098741ed30961900e84293': '1980,',\n",
       " '5726225d271a42140099d4c7': 'Recognition.',\n",
       " '57295e513f37b319004782be': 'widen',\n",
       " '56de7251cffd8e1900b4b910': 'Ottoman',\n",
       " '570cc5e1b3d812140066d26e': 'Maryam',\n",
       " '56ce8bfbaab44d1400b88869': 'connector,',\n",
       " '57264c62dd62a815002e80d0': 'rare.',\n",
       " '56e8ea980b45c0140094cd62': 'Royal',\n",
       " '5719e54410f8ca1400304e90': 'Seattle,',\n",
       " '572689e65951b619008f7638': 'Hyde',\n",
       " '57112804a58dae1900cd6cd0': 'System\"',\n",
       " '572fffeb947a6a140053cf3a': 'glass',\n",
       " '570d12d8b3d812140066d3e0': 'system.',\n",
       " '5726fae6f1498d1400e8f1ba': '\"Youth',\n",
       " '570d1b93fed7b91900d45c1f': 'monastery,',\n",
       " '5727fd7e2ca10214002d9ac9': 'advertise,',\n",
       " '57286c3b3acd2414000df9cc': 'actions:',\n",
       " '57264d1a5951b619008f6f5d': '1977.',\n",
       " '5706b77e0eeca41400aa0d90': 'asylum.',\n",
       " '572fe7abb2c2fd1400568598': 'Hannibal',\n",
       " '5726320889a1e219009ac545': 'academia',\n",
       " '5731c2fd0fdd8d15006c6516': 'compounds.',\n",
       " '56d3ab7e2ccc5a1400d82dfc': 'Pollini',\n",
       " '570b260c6b8089140040f793': '2,',\n",
       " '5726262f89a1e219009ac3dd': 'gas',\n",
       " '5733948e4776f41900660dd3': 'Supportive-teacher.',\n",
       " '56ddee7066d3e219004dae27': '1378.',\n",
       " '572f81e104bcaa1900d76a2d': 'Dam',\n",
       " '572b7b86be1ee31400cb83db': 'cement.',\n",
       " '56f9df829b226e1400dd15d5': 'France',\n",
       " '56d8e547dc89441400fdb3a2': 'Trocadéro.\"',\n",
       " '572c010e750c471900ed4c74': 'Shem',\n",
       " '570b92846b8089140040f99e': 'infrared,',\n",
       " '571b532132177014007ea06f': 'meteorites.',\n",
       " '572805d92ca10214002d9bcc': 'Lords,',\n",
       " '572ea6d5cb0c0d14000f13f1': 'Spanish,',\n",
       " '5727ce3d2ca10214002d96d8': 'Rhine,',\n",
       " '56de65324396321400ee2880': \"Plymouth's\",\n",
       " '573357204776f41900660853': 'mismatch,',\n",
       " '570d65fafed7b91900d45fdb': 'charges,',\n",
       " '572778495951b619008f8aad': 'Talmud.',\n",
       " '5731a1d3b9d445190005e41c': 'videos.',\n",
       " '56e11661e3433e1400422bb6': 'established;',\n",
       " '56cee003aab44d1400b88bb5': '400,000',\n",
       " '572ff6f7a23a5019007fcbc6': 'Arizona',\n",
       " '56df8e3e38dc421700152042': 'acoustic',\n",
       " '5726b3445951b619008f7afc': 'Road.',\n",
       " '56cf39b4aab44d1400b88eb0': '12%',\n",
       " '572f88c2a23a5019007fc705': '\"Hyderabadi\",',\n",
       " '56d3a9bb2ccc5a1400d82ddc': 'Michel',\n",
       " '56e8f8170b45c0140094cda7': 'George',\n",
       " '57310ae3e6313a140071cba3': \"officer's\",\n",
       " '570a3bf74103511400d595de': 'malt;',\n",
       " '57302473947a6a140053d189': 'vertically,',\n",
       " '573011bba23a5019007fccf7': 'history.',\n",
       " '5726aeecdd62a815002e8ce4': 'hunting)',\n",
       " '56de05334396321400ee2552': 'Aramaic',\n",
       " '572a1dd76aef0514001552b1': 'Vincent',\n",
       " '5726bb11708984140094cf7c': '20',\n",
       " '5727add53acd2414000de96d': 'Design',\n",
       " '5727c79f3acd2414000dec2d': 'two',\n",
       " '56e76d0b00c9c71400d77119': 'two',\n",
       " '56d23abcb329da140004ec28': 'imperatives,',\n",
       " '5727df9eff5b5019007d9738': 'church',\n",
       " '5726a292dd62a815002e8b96': '1765',\n",
       " '570d72f3b3d812140066d961': 'conscripts.',\n",
       " '572882433acd2414000dfa69': 'dissolved,',\n",
       " '5726a572dd62a815002e8be5': 'Zénobe',\n",
       " '5725c97d89a1e219009abea5': 'mediterranean.',\n",
       " '5731c36fb9d445190005e515': 'Official',\n",
       " '56d4c4e72ccc5a1400d8321c': 'four',\n",
       " '5727c7343acd2414000dec25': '\"tuberculin\".',\n",
       " '56f8c6e09b226e1400dd0fa7': 'executives.',\n",
       " '5726d4d1708984140094d2ac': 'infringement',\n",
       " '56df5a8096943c1400a5d412': 'people.',\n",
       " '57303157b2c2fd1400568a3a': '(SWR)',\n",
       " '56ddd60966d3e219004dad16': 'Standard,',\n",
       " '56e172f5cd28a01900c67956': 'universities.',\n",
       " '572a2b011d046914007797fc': '(Tamers’',\n",
       " '572b8fb7be1ee31400cb843e': 'media',\n",
       " '5705ed1c52bb8914006896c2': 'January.',\n",
       " '56f8c9d29e9bad19000a04f3': 'replication.:5.2',\n",
       " '56fc38192603e7140040a026': 'Jakobson,',\n",
       " '572675045951b619008f7323': '1807,',\n",
       " '572aa473be1ee31400cb8109': 'Cfa).',\n",
       " '57096a98200fba1400367f93': 'Singh',\n",
       " '573364444776f4190066099f': 'saved.\"',\n",
       " '57279c29708984140094e22e': 'Belt),',\n",
       " '56cf7b8a4df3c31400b0d821': 'Carlsbad,',\n",
       " '5728005f4b864d19001641ca': '1939,',\n",
       " '572832df4b864d19001646fb': 'Coop',\n",
       " '57101b41a58dae1900cd689a': 'homosexuality',\n",
       " '5726ffd85951b619008f845a': 'Barrow',\n",
       " '56e7415337bdd419002c3e03': 'DST',\n",
       " '570b4b85ec8fbc190045b96a': '100',\n",
       " '5726dc26708984140094d3e5': 'tree),',\n",
       " '57301cee947a6a140053d120': 'damage',\n",
       " '5727d6b4ff5b5019007d9689': '1332',\n",
       " '5730425604bcaa1900d77426': 'Economy,',\n",
       " '570b64986b8089140040f91d': 'conquistador,',\n",
       " '5705e78f75f01819005e7734': 'northern',\n",
       " '5726344989a1e219009ac568': 'Castorocauda,',\n",
       " '570ce1bab3d812140066d2e1': 'requirements.',\n",
       " '5727d7343acd2414000dede3': 'damage.',\n",
       " '56dfba0f231d4119001abd22': 'needed][citation',\n",
       " '57284b802ca10214002da267': 'Slim,',\n",
       " '5705f53452bb891400689738': '10,000',\n",
       " '57280ab8ff5b5019007d9ba0': 'century,',\n",
       " '572f4374947a6a140053c833': 'monocots.',\n",
       " '572fb096a23a5019007fc8a2': 'lipoproteins.',\n",
       " '573445d3879d6814001ca45c': 'two',\n",
       " '5729281f6aef051400154ae8': 'law\"',\n",
       " '5727d3a5ff5b5019007d9640': 'thousand',\n",
       " '572653eedd62a815002e81a5': 'Minister',\n",
       " '5727c7343acd2414000dec27': '\"tuberculin\".',\n",
       " '572f99a7a23a5019007fc7c3': '84%',\n",
       " '56d00bc5234ae51400d9c2cd': '1927.',\n",
       " '57286c3b3acd2414000df9cd': 'Henderson)',\n",
       " '5734195bd058e614000b694d': 'identity,',\n",
       " '57345714acc1501500babe1a': 'monthly,',\n",
       " '572f83ae947a6a140053c9fa': 'in.',\n",
       " '572ea6d5cb0c0d14000f13f0': 'Spanish,',\n",
       " '56dfba5f231d4119001abd2d': 'alehouses.',\n",
       " '57070e0c9e06ca38007e9342': 'Punch,',\n",
       " '57279b65ff5b5019007d90dd': '78',\n",
       " '56db43dae7c41114004b4fe0': '11%',\n",
       " '573407b6d058e614000b680b': '65%',\n",
       " '5726ceaa5951b619008f7e94': 'Nicholas',\n",
       " '57326292e17f3d1400422929': 'Spain',\n",
       " '5733b5344776f419006610df': '\"one',\n",
       " '56e1500fcd28a01900c677a5': 'University,',\n",
       " '56d8dd47dc89441400fdb358': 'April',\n",
       " '570dfd080b85d914000d7c69': 'radiation.',\n",
       " '572940fe6aef051400154bfd': 'Native',\n",
       " '572ee270c246551400ce4778': '2,700',\n",
       " '56e14735cd28a01900c67721': '1669',\n",
       " '56e73fb737bdd419002c3dfb': 'March,',\n",
       " '57342a56d058e614000b6a81': 'Bacchus.',\n",
       " '5726fde1708984140094d7dd': 'rights.',\n",
       " '56f7f909a6d7ea1400e17343': 'nobility,',\n",
       " '5729223faf94a219006aa0d7': 'grey-box,',\n",
       " '56df9c2a38dc4217001520da': 'male.',\n",
       " '56fb80258ddada1400cd6493': 'Arthur.',\n",
       " '572fbd86b2c2fd14005683cc': '£6.3',\n",
       " '56fb853fb28b3419009f1df0': '909,',\n",
       " '56fc2c4e00a8df19004037bf': 'phonemics,',\n",
       " '5728027a4b864d190016420b': 'encodings.',\n",
       " '56de6a2e4396321400ee28ad': '40',\n",
       " '573155a6a5e9cc1400cdbea6': 'white.',\n",
       " '5727a4b74b864d190016392f': '15',\n",
       " '57096d77200fba1400367fce': 'dialectics',\n",
       " '572a1b551d04691400779794': 'motion.',\n",
       " '572f139a03f9891900756b76': '60',\n",
       " '57293720af94a219006aa1ae': 'Edwards',\n",
       " '57273164708984140094dac9': 'Proper,',\n",
       " '56f95bb59b226e1400dd13a2': 'Atoll',\n",
       " '5727f2323acd2414000df07d': '$17,200.',\n",
       " '5727b7e24b864d1900163b54': 'functional.',\n",
       " '56f734e03d8e2e1400e3746c': 'implied,',\n",
       " '56fb7d088ddada1400cd646e': 'remained,',\n",
       " '56fa115c8f12f319006300bd': 'dry.',\n",
       " '570b1cf5ec8fbc190045b830': 'packets,',\n",
       " '572827c83acd2414000df5b7': 'four',\n",
       " '56f8ca819b226e1400dd100e': 'ten',\n",
       " '5728b7453acd2414000dfd39': 'subdivision.',\n",
       " '572b520df75d5e190021fd87': 'zinc',\n",
       " '56dd2d7d9a695914005b9534': '1905.',\n",
       " '5726769ff1498d1400e8e088': 'operatives,',\n",
       " '572e9eb603f9891900756841': 'Sun',\n",
       " '57267966708984140094c74d': 'Turri,',\n",
       " '570d710ffed7b91900d46109': '1858',\n",
       " '571ad0d09499d21900609b3d': 'Novello',\n",
       " '5728daea3acd2414000e0057': 'Mongoloid',\n",
       " '56df983d38dc4217001520ac': 'City,',\n",
       " '5735137e879d6814001cab04': 'areas,',\n",
       " '5725c843ec44d21400f3d55f': '13%',\n",
       " '5726e0d2f1498d1400e8ee6f': 'missing,',\n",
       " '5726e200708984140094d4ab': 'William',\n",
       " '570c4ce1b3d812140066d09b': 'Eleanor,',\n",
       " '570a7b204103511400d59763': 'emotions.',\n",
       " '572ebc9303f98919007569c3': 'kings—the',\n",
       " '56d4bc242ccc5a1400d8318b': 'wicga',\n",
       " '56fb879b8ddada1400cd64d3': 'Death,',\n",
       " '5726a4cd708984140094ccc0': 'Polynesia',\n",
       " '572a9ed7f75d5e190021fbb0': '1835,',\n",
       " '56e18a90e3433e1400422fab': 'Barcelona',\n",
       " '56de9a164396321400ee2a49': 'John',\n",
       " '56d384b059d6e41400146605': 'guitar\"',\n",
       " '572f8ba7b2c2fd14005681e0': '1071',\n",
       " '57270731dd62a815002e97fb': 'capacitors,',\n",
       " '5726ec1cf1498d1400e8efed': '5%',\n",
       " '56de3ba64396321400ee26b8': '14th',\n",
       " '5730a824396df91900096250': '\"Sumerian\"',\n",
       " '56e7a35800c9c71400d77462': 'Vegas',\n",
       " '56f977009b226e1400dd1478': '(Personnel).',\n",
       " '5733f3694776f41900661594': 'Office',\n",
       " '57334d024776f41900660816': 'originators,',\n",
       " '56ce64a8aab44d1400b88745': 'polyethylene',\n",
       " '573181eee6313a140071cfdd': 'art,',\n",
       " '572f527db2c2fd140056801f': '1901,',\n",
       " '572967616aef051400154e26': 'Subsidies',\n",
       " '5710a972a58dae1900cd6aee': 'northern',\n",
       " '572b550a34ae481900dead8f': 'zinc',\n",
       " '570c31e36b8089140040fc0e': 'mid-1960s,',\n",
       " '5706233475f01819005e79e1': 'ISO',\n",
       " '56cfbc57234ae51400d9bf31': 'century,',\n",
       " '57315ef905b4da19006bd108': 'taxes',\n",
       " '5726e540dd62a815002e9444': 'morphosyllabic,',\n",
       " '56de8c374396321400ee2a13': 'DeVito,',\n",
       " '570dfbd20b85d914000d7c5a': 'meteorites.',\n",
       " '57269193f1498d1400e8e412': 'Taunton',\n",
       " '5709b165ed30961900e84427': 'now;',\n",
       " '56cece5caab44d1400b88a9d': '(US$113,000)',\n",
       " '56d65a4b1c850414009470b0': 'collapses.',\n",
       " '571aa61910f8ca1400305267': 'Egypt.',\n",
       " '5726a33e708984140094cc9f': '4,000',\n",
       " '5727757edd62a815002e9d50': 'Sephardim.',\n",
       " '572655ecdd62a815002e81dc': 'made,',\n",
       " '570ab07c4103511400d5993f': '1962',\n",
       " '56dfc2b77aa994140058e153': 'ones,',\n",
       " '5726bf4d708984140094d039': 'subject–verb–object',\n",
       " '56dd006d66d3e219004dabb2': '65%',\n",
       " '571a11c84faf5e1900b8a88e': 'Orchestra',\n",
       " '5728c068ff5b5019007da5fa': 'Victoires,',\n",
       " '572814b94b864d1900164414': '38',\n",
       " '56e7a35800c9c71400d77461': 'Gladiators.',\n",
       " '5731b5b50fdd8d15006c6471': '1657',\n",
       " ...}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-da60b62b4d7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0meval_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model_on_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparagraphs_mapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquestions_mapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-d5d74829da8a>\u001b[0m in \u001b[0;36mevaluate_model_on_data\u001b[0;34m(model, evaluator, dataloader, paragraphs_mapper, questions_mapper, device, debug)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mevaluate_model_on_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparagraphs_mapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquestions_mapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0meval_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_evaluation_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparagraphs_mapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquestions_mapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"DEBUG: Eval_dict: {eval_dict}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/uni/magistrale_ai/secondo_anno/nlp/project/SQuAD-QA/evaluation/utils.py\u001b[0m in \u001b[0;36mbuild_evaluation_dict\u001b[0;34m(model, dataloader, paragraphs_mapper, questions_mapper, device)\u001b[0m\n\u001b[1;32m     39\u001b[0m                 \u001b[0mpred_span_start_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred_span_start_idxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m                 \u001b[0mpred_span_end_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred_span_end_idxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m                 pred_answer_text = extract_answer(paragraphs_mapper[paragraph_sample_id],\n\u001b[0m\u001b[1;32m     42\u001b[0m                                                   \u001b[0mpred_span_start_sample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m                                                   pred_span_end_sample)\n",
      "\u001b[0;32m~/uni/magistrale_ai/secondo_anno/nlp/project/SQuAD-QA/evaluation/utils.py\u001b[0m in \u001b[0;36mextract_answer\u001b[0;34m(paragraph_tokens, start_idx, end_idx)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0manswer_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstart_idx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mend_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0manswer_tokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparagraph_tokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_idx\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstart_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparagraph_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstart_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "eval_results = evaluate_model_on_data(model, evaluator, train_data_loader, paragraphs_mapper, questions_mapper, device, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "NLP_Project.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "squad_qa_pytorch",
   "language": "python",
   "name": "squad_qa_pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
