{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/alexpod1000/SQuAD-QA/blob/main/ModelTrainExperimentalCode.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "oTkVfFrJ-pzG"
   },
   "outputs": [],
   "source": [
    "#%%bash\n",
    "#[[ ! -e /colabtools ]] && exit  # Continue only if running on Google Colab\n",
    "\n",
    "# Clone repository\n",
    "# https://sysadmins.co.za/clone-a-private-github-repo-with-personal-access-token/\n",
    "# For cloning the main branch:\n",
    "#!git clone https://fb5b65b126107273e595ce8b6c9d2d533103c6e2:x-oauth-basic@github.com/alexpod1000/SQuAD-QA.git\n",
    "# For cloning the \"evaluation-features\" branch\n",
    "#!git clone --branch evaluation-features https://fb5b65b126107273e595ce8b6c9d2d533103c6e2:x-oauth-basic@github.com/alexpod1000/SQuAD-QA.git\n",
    "# Change current working directory to match project\n",
    "#%cd SQuAD-QA/\n",
    "#!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "rsBVuJu6_5qN"
   },
   "outputs": [],
   "source": [
    "# External imports\n",
    "import copy\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import torch\n",
    "\n",
    "from functools import partial\n",
    "from nltk.tokenize import TreebankWordTokenizer, SpaceTokenizer\n",
    "from transformers import AutoTokenizer\n",
    "from typing import Tuple, List, Dict, Any, Union\n",
    "\n",
    "# Project imports\n",
    "from squad_data.parser import SquadFileParser\n",
    "from squad_data.utils import build_mappers_and_dataframe_bert\n",
    "from evaluation.evaluation_metrics import Evaluator\n",
    "from evaluation.utils import extract_answer, build_evaluation_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "387a021D9piE"
   },
   "source": [
    "### Download Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xFweP2uIJg8O",
    "outputId": "7bb5b9ca-7b89-4fad-dc90-c979f6ef5f0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-downloaded embeddings from /home/alexpod/uni/magistrale_ai/secondo_anno/nlp/project/SQuAD-QA/embedding_models/embedding_model.kv\n",
      "End!\n",
      "Embedding dimension: 300\n"
     ]
    }
   ],
   "source": [
    "from utils.embedding_utils import EmbeddingDownloader\n",
    "\n",
    "embedding_downloader = EmbeddingDownloader(\n",
    "    \"embedding_models\", \n",
    "    \"embedding_model.kv\", \n",
    "    model_name=\"fasttext-wiki-news-subwords-300\"\n",
    ")\n",
    "\n",
    "embedding_model = embedding_downloader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Rh4dSW-9tYm"
   },
   "source": [
    "### Parse the json and get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "FAEEYoypAOKA"
   },
   "outputs": [],
   "source": [
    "#parser = SquadFileParser(\"squad_data/data/training_set.json\")\n",
    "parser = SquadFileParser(\"squad_data/data/dev-v1.1.json\")\n",
    "data = parser.parse_documents()\n",
    "\n",
    "########################### DEBUG\n",
    "# reduce size for faster testing\n",
    "#full_data = data\n",
    "#data = []\n",
    "#for i in range(1): # use only the first 1 documents\n",
    "#  data.append(full_data[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SKK-4d1_93QE"
   },
   "source": [
    "### Prepare the mappers and datafram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_tokenizer_fn(question, paragraph, tokenizer, max_length=384, doc_stride=128):\n",
    "    pad_on_right = tokenizer.padding_side == \"right\"\n",
    "    # Process the sample\n",
    "    tokenized_input_pair = tokenizer(\n",
    "        question,\n",
    "        paragraph,\n",
    "        truncation=\"only_second\" if pad_on_right else \"only_first\",\n",
    "        max_length=max_length,\n",
    "        stride=doc_stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    return tokenized_input_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "tokenizer_fn_preprocess = partial(bert_tokenizer_fn, tokenizer=tokenizer, max_length=380)\n",
    "tokenizer_fn_train = partial(bert_tokenizer_fn, tokenizer=tokenizer, max_length=384)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "super bowl 50 was an american football game to determine the champion of the national football league ( nfl ) for the 2015 season. the american football conference ( afc ) champion denver broncos defeated the national football conference ( nfc ) champion carolina panthers 24 – 10 to earn their third super bowl title. the game was played on february 7, 2016, at levi's stadium in the san francisco bay area at santa clara, california. as this was the 50th super bowl, the league emphasized the \" golden anniversary \" with various gold - themed initiatives, as well as temporarily suspending the tradition of naming each super bowl game with roman numerals ( under which the game would have been known as \" super bowl l \" ), so that the logo could prominently feature the arabic numerals 50.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paragraph_id</th>\n",
       "      <th>question_id</th>\n",
       "      <th>answer_id</th>\n",
       "      <th>answer_start</th>\n",
       "      <th>answer_text</th>\n",
       "      <th>question_text</th>\n",
       "      <th>tokenizer_answer_start</th>\n",
       "      <th>tokenizer_answer_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_0</td>\n",
       "      <td>56be4db0acb8001400a502ec</td>\n",
       "      <td>0</td>\n",
       "      <td>177</td>\n",
       "      <td>Denver Broncos</td>\n",
       "      <td>Which NFL team represented the AFC at Super Bo...</td>\n",
       "      <td>46</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_0</td>\n",
       "      <td>56be4db0acb8001400a502ed</td>\n",
       "      <td>0</td>\n",
       "      <td>249</td>\n",
       "      <td>Carolina Panthers</td>\n",
       "      <td>Which NFL team represented the NFC at Super Bo...</td>\n",
       "      <td>57</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_0</td>\n",
       "      <td>56be4db0acb8001400a502ee</td>\n",
       "      <td>0</td>\n",
       "      <td>403</td>\n",
       "      <td>Santa Clara, California</td>\n",
       "      <td>Where did Super Bowl 50 take place?</td>\n",
       "      <td>89</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_0</td>\n",
       "      <td>56be4db0acb8001400a502ef</td>\n",
       "      <td>0</td>\n",
       "      <td>177</td>\n",
       "      <td>Denver Broncos</td>\n",
       "      <td>Which NFL team won Super Bowl 50?</td>\n",
       "      <td>43</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0_0</td>\n",
       "      <td>56be4db0acb8001400a502f0</td>\n",
       "      <td>0</td>\n",
       "      <td>488</td>\n",
       "      <td>gold</td>\n",
       "      <td>What color was used to emphasize the 50th anni...</td>\n",
       "      <td>112</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  paragraph_id               question_id  answer_id  answer_start  \\\n",
       "0          0_0  56be4db0acb8001400a502ec          0           177   \n",
       "1          0_0  56be4db0acb8001400a502ed          0           249   \n",
       "2          0_0  56be4db0acb8001400a502ee          0           403   \n",
       "3          0_0  56be4db0acb8001400a502ef          0           177   \n",
       "4          0_0  56be4db0acb8001400a502f0          0           488   \n",
       "\n",
       "               answer_text                                      question_text  \\\n",
       "0           Denver Broncos  Which NFL team represented the AFC at Super Bo...   \n",
       "1        Carolina Panthers  Which NFL team represented the NFC at Super Bo...   \n",
       "2  Santa Clara, California                Where did Super Bowl 50 take place?   \n",
       "3           Denver Broncos                  Which NFL team won Super Bowl 50?   \n",
       "4                     gold  What color was used to emphasize the 50th anni...   \n",
       "\n",
       "   tokenizer_answer_start  tokenizer_answer_end  \n",
       "0                      46                    48  \n",
       "1                      57                    59  \n",
       "2                      89                    93  \n",
       "3                      43                    45  \n",
       "4                     112                   114  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraphs_mapper, df = build_mappers_and_dataframe_bert(tokenizer, tokenizer_fn_preprocess, data, limit_answers=1)\n",
    "print(paragraphs_mapper[next(iter(paragraphs_mapper))])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xb4YK_Qa95zK"
   },
   "source": [
    "### DataConverter and CustomQADataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KDl4CIW-mj_D",
    "outputId": "f012b0d4-f66e-4917-c208-1ebebe9a2f23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 384])\n",
      "torch.Size([10, 2])\n"
     ]
    }
   ],
   "source": [
    "from data_loading.utils import bert_padder_collate_fn\n",
    "from data_loading.qa_dataset import CustomQADatasetBERT\n",
    "\n",
    "datasetQA = CustomQADatasetBERT(tokenizer_fn_train, df, paragraphs_mapper)\n",
    "data_loader = torch.utils.data.DataLoader(datasetQA, collate_fn = bert_padder_collate_fn, batch_size=10, shuffle=True)\n",
    "\n",
    "test_batch = next(iter(data_loader))\n",
    "print(test_batch[\"input_ids\"].shape)\n",
    "print(test_batch[\"y_gt\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nNOTE: this logic is used for sample creation only, such that each sample is \"short enough\" for BERT; \\n      a duplicate of this logic will need to be used in QADataset Dataloader class when we\\'ll take\\n      short samples\\' text, tokenize them again, and find the correct index\\nALTERNATIVE: for BERT models we could directly get the answer spans, and pass them in dataframe to another QADataset\\n             built specifically for BERT, that will just take the data from dataframe (way nicer and faster solution).\\nSUGGESTION: we could also use specific dict keys and in QADataset pick stuff from these keys: \\n                - if these keys are absent then don\\'t use BERT logic (eg span_start and span_end) and use previous logic\\n                - if these keys are present, then just use them and gather the BERT samples.\\n                Call these keys like \"tokenizer_span_idx\" (to make them kinda unique)\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "NOTE: this logic is used for sample creation only, such that each sample is \"short enough\" for BERT; \n",
    "      a duplicate of this logic will need to be used in QADataset Dataloader class when we'll take\n",
    "      short samples' text, tokenize them again, and find the correct index\n",
    "ALTERNATIVE: for BERT models we could directly get the answer spans, and pass them in dataframe to another QADataset\n",
    "             built specifically for BERT, that will just take the data from dataframe (way nicer and faster solution).\n",
    "SUGGESTION: we could also use specific dict keys and in QADataset pick stuff from these keys: \n",
    "                - if these keys are absent then don't use BERT logic (eg span_start and span_end) and use previous logic\n",
    "                - if these keys are present, then just use them and gather the BERT samples.\n",
    "                Call these keys like \"tokenizer_span_idx\" (to make them kinda unique)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import transformers\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "from tqdm import tqdm\n",
    "from transformers.optimization import AdamW\n",
    "\n",
    "from models.utils import SpanExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The device is cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"The device is {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model:\n",
    "\n",
    "(input_ids, attention_mask) -> (answer_start, answer_end) // for each token in input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, optimizer, loss_function, dataloader, device=\"cpu\", show_progress=False):\n",
    "    acc_loss = 0\n",
    "    acc_start_accuracy = 0\n",
    "    acc_end_accuracy = 0\n",
    "    count = 0\n",
    "\n",
    "    time_start = timer()\n",
    "    \n",
    "    model.train()\n",
    "    wrapped_dataloader = tqdm(dataloader) if show_progress else dataloader\n",
    "    for batch in wrapped_dataloader:\n",
    "        # NOTE: we'll pass directly the batch dict to the model for inputs.\n",
    "        answer_spans_start = batch[\"y_gt\"][:, 0]\n",
    "        answer_spans_end = batch[\"y_gt\"][:, 1]\n",
    "        # Clear gradients\n",
    "        model.zero_grad()\n",
    "        # Place to right device\n",
    "        answer_spans_start = answer_spans_start.to(device)\n",
    "        answer_spans_end = answer_spans_end.to(device)\n",
    "        # Run forward pass\n",
    "        pred_answer_start_scores, pred_answer_end_scores = model(batch)\n",
    "        # Compute the CrossEntropyLoss\n",
    "        loss = loss_function(pred_answer_start_scores, answer_spans_start) + loss_function(pred_answer_end_scores, answer_spans_end)\n",
    "        # Compute gradients\n",
    "        loss.backward()\n",
    "        # Optimizer step\n",
    "        optimizer.step()\n",
    "        # --- Compute metrics ---\n",
    "        # Get span indexes\n",
    "        pred_span_start_idxs, pred_span_end_idxs = SpanExtractor.extract_most_probable(pred_answer_start_scores, pred_answer_end_scores)\n",
    "        gt_start_idxs = answer_spans_start.cpu().detach()\n",
    "        gt_end_idxs = answer_spans_end.cpu().detach()\n",
    "        # two accs\n",
    "        start_accuracy = torch.sum(gt_start_idxs == pred_span_start_idxs) / len(pred_span_start_idxs)\n",
    "        end_accuracy = torch.sum(gt_end_idxs == pred_span_end_idxs) / len(pred_span_end_idxs)\n",
    "        # Gather stats\n",
    "        acc_loss += loss.item()\n",
    "        acc_start_accuracy += start_accuracy.item()\n",
    "        acc_end_accuracy += end_accuracy.item()\n",
    "        count += 1\n",
    "    time_end = timer()\n",
    "    return {\n",
    "        \"loss\": acc_loss / count, \n",
    "        \"accuracy_start\": acc_start_accuracy / count, \n",
    "        \"accuracy_end\": acc_end_accuracy / count,\n",
    "        \"time\": time_end - time_start\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Evaluator object\n",
    "evaluator = Evaluator(documents_list=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_on_data(model, evaluator, dataloader, paragraphs_mapper, device, debug=False):\n",
    "    # TODO(Alex): evaluation needs to be fixed (the spans are not computed on tokens for now)\n",
    "    eval_dict = build_evaluation_dict(model, dataloader, paragraphs_mapper, device)\n",
    "    if debug:\n",
    "        print(f\"DEBUG: Eval_dict: {eval_dict}\")\n",
    "    stats = {}\n",
    "    stats['exact_match'] = evaluator.ExactMatch(eval_dict)\n",
    "    stats['f1'] = evaluator.F1(eval_dict)\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistilBertBaseQA(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_size, num_labels):\n",
    "        super(DistilBertBaseQA, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_labels = num_labels\n",
    "        self.config = transformers.DistilBertConfig(max_position_embeddings=384)\n",
    "        #self.bert = transformers.DistilBertModel(bert_config)\n",
    "        self.bert = transformers.DistilBertModel.from_pretrained('distilbert-base-uncased')#(bert_config)\n",
    "        self.qa_outputs = torch.nn.Linear(self.hidden_size, self.num_labels)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # --- 1) Extract data from inputs dictionary and put it on right device\n",
    "        curr_device = self.bert.device\n",
    "        input_ids = inputs[\"input_ids\"].to(curr_device)\n",
    "        attention_mask = inputs[\"attention_mask\"].to(curr_device)\n",
    "        # --- 2) Run BERT backbone to produce final representation\n",
    "        output = self.bert(input_ids = input_ids, attention_mask = attention_mask)\n",
    "        # --- 3) On top of the final representation, run a mapper to get scores for each position.\n",
    "        sequence_output = output[0]   #(None, seq_len, hidden_size)\n",
    "        logits = self.qa_outputs(sequence_output) #(None, seq_len, hidden_size)*(hidden_size, 2)=(None, seq_len, 2)\n",
    "        start_logits, end_logits = logits.split(1, dim=-1)    #(None, seq_len, 1), (None, seq_len, 1)\n",
    "        start_logits = start_logits.squeeze(-1)  #(None, seq_len)\n",
    "        end_logits = end_logits.squeeze(-1)    #(None, seq_len)\n",
    "        # --- 4) Prepare output tuple\n",
    "        outputs = (start_logits, end_logits,) \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define baseline model\n",
    "model = DistilBertBaseQA(768, 2).to(device)\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = AdamW(model.parameters(), lr=0.00001, correct_bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetQA = CustomQADatasetBERT(tokenizer_fn_train, df, paragraphs_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader = torch.utils.data.DataLoader(datasetQA, collate_fn = bert_padder_collate_fn, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 674/674 [04:08<00:00,  2.71it/s]\n",
      "  0%|          | 0/674 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, lr: 1e-05, Train loss: 5.0738,  Train acc start: 0.3849, Train acc end: 0.3803, Time: 248.5143\n",
      "Evaluation Results: {'exact_match': 0.0, 'f1': 0.3773711205146364}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 21/674 [00:08<04:15,  2.56it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-412de2c84533>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mscheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReduceLROnPlateau\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtrain_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_progress\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0meval_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model_on_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparagraphs_mapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mcur_lr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-27729beae2de>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(model, optimizer, loss_function, dataloader, device, show_progress)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_answer_start_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswer_spans_start\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_answer_end_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswer_spans_end\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m# Compute gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0;31m# Optimizer step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/squad_qa_pytorch/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/squad_qa_pytorch/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = {\"train_loss\": [], \"train_acc_start\": [], \"train_acc_end\": []}\n",
    "loop_start = timer()\n",
    "# lr scheduler\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=5, threshold=0.01)\n",
    "for epoch in range(50):\n",
    "    train_dict = train_step(model, optimizer, loss_function, train_data_loader, device=device, show_progress=True)\n",
    "    eval_results = evaluate_model_on_data(model, evaluator, train_data_loader, paragraphs_mapper, device, debug=False)\n",
    "    cur_lr = optimizer.param_groups[0]['lr']\n",
    "    print(f'Epoch: {epoch}, lr: {cur_lr}, Train loss: {train_dict[\"loss\"]:.4f},  Train acc start: {train_dict[\"accuracy_start\"]:.4f}, Train acc end: {train_dict[\"accuracy_end\"]:.4f}, Time: {train_dict[\"time\"]:.4f}')\n",
    "    history[\"train_loss\"].append(train_dict[\"loss\"]);history[\"train_acc_start\"].append(train_dict[\"accuracy_start\"]);history[\"train_acc_end\"].append(train_dict[\"accuracy_end\"]);\n",
    "    #history[\"val_loss\"].append(val_dict[\"loss\"]);history[\"val_acc\"].append(val_dict[\"accuracy\"]);\n",
    "    #scheduler.step(val_dict[\"loss\"])\n",
    "    print(f\"Evaluation Results: {eval_results}\")\n",
    "loop_end = timer()\n",
    "print(f\"Elapsed time: {(loop_end - loop_start):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple qualitative evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer_span_helper(context, question, model, tokenizer_fn, tokenizer, device=\"cpu\"):\n",
    "    tokenized_input = tokenizer_fn(question, context)\n",
    "    output_span = model({\n",
    "        \"input_ids\": torch.tensor(tokenized_input[\"input_ids\"]).to(device), \n",
    "        \"attention_mask\": torch.tensor(tokenized_input[\"attention_mask\"]).to(device)\n",
    "    })\n",
    "    start, end = SpanExtractor.extract_most_probable(output_span[0], output_span[1])\n",
    "    start = start.item()\n",
    "    end = end.item()\n",
    "    return tokenizer.decode(tokenized_input[\"input_ids\"][0][start:end], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "our model\n"
     ]
    }
   ],
   "source": [
    "context = \"This is a test message, written to see if our model can correctly predict its outputs.\"\n",
    "question = \"Who needs to predict its outputs?\"\n",
    "pred_answer = get_answer_span_helper(context, question, model, tokenizer_fn_train, tokenizer, device=\"cuda\")\n",
    "print(pred_answer)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "NLP_Project.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "squad_qa_pytorch",
   "language": "python",
   "name": "squad_qa_pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
