{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/alexpod1000/SQuAD-QA/blob/main/Train_model_GPU_BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "oTkVfFrJ-pzG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'SQuAD-QA'...\n",
      "remote: Enumerating objects: 396, done.\u001b[K\n",
      "remote: Counting objects: 100% (24/24), done.\u001b[K\n",
      "remote: Compressing objects: 100% (24/24), done.\u001b[K\n",
      "remote: Total 396 (delta 8), reused 3 (delta 0), pack-reused 372\u001b[K\n",
      "Receiving objects: 100% (396/396), 9.15 MiB | 3.74 MiB/s, done.\n",
      "Resolving deltas: 100% (233/233), done.\n",
      "/home/alexpod/projects/SQuAD-QA/SQuAD-QA\n",
      "/home/alexpod/projects/SQuAD-QA/SQuAD-QA\n",
      "Collecting transformers\n",
      "^C\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Run the following cells only if using Colab\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    # Clone repository\n",
    "    !git clone https://github.com/alexpod1000/SQuAD-QA.git\n",
    "    # Change current working directory to match project\n",
    "    %cd SQuAD-QA/\n",
    "    !pwd\n",
    "\n",
    "    !pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "rsBVuJu6_5qN"
   },
   "outputs": [],
   "source": [
    "# External imports\n",
    "import copy\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import torch\n",
    "import json\n",
    "\n",
    "from functools import partial\n",
    "from nltk.tokenize import TreebankWordTokenizer, SpaceTokenizer\n",
    "from transformers import AutoTokenizer\n",
    "from typing import Tuple, List, Dict, Any, Union\n",
    "\n",
    "# Project imports\n",
    "from squad_data.parser import SquadFileParser\n",
    "from squad_data.utils import build_mappers_and_dataframe_bert\n",
    "from models import possible_models_dict\n",
    "from evaluation.evaluate import evaluate_predictions\n",
    "from evaluation.utils import build_evaluation_dict_bert\n",
    "from utils import split_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#current_selected_experiment = \"distilbert\"\n",
    "#current_selected_experiment = \"bert\"\n",
    "#current_selected_experiment = \"albert\"\n",
    "#current_selected_experiment = \"distilroberta\"\n",
    "current_selected_experiment = \"distilroberta_extra_linear\"\n",
    "params_dict = possible_models_dict[current_selected_experiment]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Rh4dSW-9tYm"
   },
   "source": [
    "### Parse the json and get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "FAEEYoypAOKA"
   },
   "outputs": [],
   "source": [
    "train_file_json = \"squad_data/data/training_set.json\"\n",
    "test_file_json = \"squad_data/data/dev-v1.1.json\"\n",
    "\n",
    "train_parser = SquadFileParser(train_file_json)\n",
    "test_parser = SquadFileParser(test_file_json)\n",
    "\n",
    "train_data = train_parser.parse_documents()\n",
    "test_data = test_parser.parse_documents()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SKK-4d1_93QE"
   },
   "source": [
    "### Prepare the mappers and datafram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_tokenizer_fn(question, paragraph, tokenizer, max_length=384, doc_stride=128):\n",
    "    pad_on_right = tokenizer.padding_side == \"right\"\n",
    "    # Process the sample\n",
    "    tokenized_input_pair = tokenizer(\n",
    "        question,\n",
    "        paragraph,\n",
    "        truncation=\"only_second\" if pad_on_right else \"only_first\",\n",
    "        max_length=max_length,\n",
    "        stride=doc_stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    return tokenized_input_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(params_dict[\"tokenizer_url\"])\n",
    "tokenizer_fn_preprocess = partial(bert_tokenizer_fn, tokenizer=tokenizer, max_length=params_dict[\"tokenizer_max_length\"]-3)\n",
    "tokenizer_fn_train = partial(bert_tokenizer_fn, tokenizer=tokenizer, max_length=params_dict[\"tokenizer_max_length\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>paragraph_id</th>\n",
       "      <th>question_id</th>\n",
       "      <th>answer_id</th>\n",
       "      <th>answer_start</th>\n",
       "      <th>answer_text</th>\n",
       "      <th>question_text</th>\n",
       "      <th>tokenizer_answer_start</th>\n",
       "      <th>tokenizer_answer_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0_0</td>\n",
       "      <td>5733be284776f41900661182</td>\n",
       "      <td>0</td>\n",
       "      <td>515</td>\n",
       "      <td>Saint Bernadette Soubirous</td>\n",
       "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
       "      <td>135</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0_0</td>\n",
       "      <td>5733be284776f4190066117f</td>\n",
       "      <td>0</td>\n",
       "      <td>188</td>\n",
       "      <td>a copper statue of Christ</td>\n",
       "      <td>What is in front of the Notre Dame Main Building?</td>\n",
       "      <td>54</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0_0</td>\n",
       "      <td>5733be284776f41900661180</td>\n",
       "      <td>0</td>\n",
       "      <td>279</td>\n",
       "      <td>the Main Building</td>\n",
       "      <td>The Basilica of the Sacred heart at Notre Dame...</td>\n",
       "      <td>81</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0_0</td>\n",
       "      <td>5733be284776f41900661181</td>\n",
       "      <td>0</td>\n",
       "      <td>381</td>\n",
       "      <td>a Marian place of prayer and reflection</td>\n",
       "      <td>What is the Grotto at Notre Dame?</td>\n",
       "      <td>96</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0_0</td>\n",
       "      <td>5733be284776f4190066117e</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "      <td>a golden statue of the Virgin Mary</td>\n",
       "      <td>What sits on top of the Main Building at Notre...</td>\n",
       "      <td>35</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   doc_id paragraph_id               question_id  answer_id  answer_start  \\\n",
       "0       0          0_0  5733be284776f41900661182          0           515   \n",
       "1       0          0_0  5733be284776f4190066117f          0           188   \n",
       "2       0          0_0  5733be284776f41900661180          0           279   \n",
       "3       0          0_0  5733be284776f41900661181          0           381   \n",
       "4       0          0_0  5733be284776f4190066117e          0            92   \n",
       "\n",
       "                               answer_text  \\\n",
       "0               Saint Bernadette Soubirous   \n",
       "1                a copper statue of Christ   \n",
       "2                        the Main Building   \n",
       "3  a Marian place of prayer and reflection   \n",
       "4       a golden statue of the Virgin Mary   \n",
       "\n",
       "                                       question_text  tokenizer_answer_start  \\\n",
       "0  To whom did the Virgin Mary allegedly appear i...                     135   \n",
       "1  What is in front of the Notre Dame Main Building?                      54   \n",
       "2  The Basilica of the Sacred heart at Notre Dame...                      81   \n",
       "3                  What is the Grotto at Notre Dame?                      96   \n",
       "4  What sits on top of the Main Building at Notre...                      35   \n",
       "\n",
       "   tokenizer_answer_end  \n",
       "0                   143  \n",
       "1                    59  \n",
       "2                    84  \n",
       "3                   103  \n",
       "4                    42  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraphs_mapper, df = build_mappers_and_dataframe_bert(tokenizer, tokenizer_fn_preprocess, train_data, limit_answers=1)\n",
    "print(paragraphs_mapper[next(iter(paragraphs_mapper))])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_val = split_dataframe(df, train_ratio=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 88579, Train samples: 80992, Validation samples: 7587\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total samples: {len(df)}, Train samples: {len(df_train)}, Validation samples: {len(df_val)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xb4YK_Qa95zK"
   },
   "source": [
    "### DataConverter and CustomQADataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KDl4CIW-mj_D",
    "outputId": "f012b0d4-f66e-4917-c208-1ebebe9a2f23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 384])\n",
      "torch.Size([10, 2])\n"
     ]
    }
   ],
   "source": [
    "from data_loading.utils import bert_padder_collate_fn\n",
    "from data_loading.qa_dataset import CustomQADatasetBERT\n",
    "\n",
    "datasetQA = CustomQADatasetBERT(tokenizer_fn_train, df_train, paragraphs_mapper)\n",
    "data_loader = torch.utils.data.DataLoader(datasetQA, collate_fn = bert_padder_collate_fn, batch_size=10, shuffle=True)\n",
    "\n",
    "test_batch = next(iter(data_loader))\n",
    "print(test_batch[\"input_ids\"].shape)\n",
    "print(test_batch[\"y_gt\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import transformers\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "from tqdm import tqdm\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from transformers.optimization import AdamW\n",
    "\n",
    "from models.utils import SpanExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The device is cuda\n",
      "Automatic Mixed Precision Enabled: True\n"
     ]
    }
   ],
   "source": [
    "use_amp = True\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"The device is {device}\")\n",
    "print(f\"Automatic Mixed Precision Enabled: {use_amp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model:\n",
    "\n",
    "(input_ids, attention_mask) -> (answer_start, answer_end) // for each token in input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, scaler, optimizer, loss_function, dataloader, scheduler=None, device=\"cpu\", show_progress=False):\n",
    "    acc_loss = 0\n",
    "    acc_start_accuracy = 0\n",
    "    acc_end_accuracy = 0\n",
    "    count = 0\n",
    "\n",
    "    time_start = timer()\n",
    "    \n",
    "    model.train()\n",
    "    wrapped_dataloader = tqdm(dataloader) if show_progress else dataloader\n",
    "    for batch in wrapped_dataloader:\n",
    "        # NOTE: we'll pass directly the batch dict to the model for inputs.\n",
    "        answer_spans_start = batch[\"y_gt\"][:, 0]\n",
    "        answer_spans_end = batch[\"y_gt\"][:, 1]\n",
    "        # Clear gradients\n",
    "        model.zero_grad()\n",
    "        # Place to right device\n",
    "        answer_spans_start = answer_spans_start.to(device)\n",
    "        answer_spans_end = answer_spans_end.to(device)\n",
    "        # Use Automatic Mixed Precision if enabled\n",
    "        with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):\n",
    "            # Run forward pass\n",
    "            pred_answer_start_scores, pred_answer_end_scores = model(batch)\n",
    "            # Compute the CrossEntropyLoss\n",
    "            loss = (loss_function(pred_answer_start_scores, answer_spans_start) + loss_function(pred_answer_end_scores, answer_spans_end))/2.0\n",
    "        scaler.scale(loss).backward()\n",
    "        # Optimizer step (via scaler)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        # Update LR scheduler\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "        # --- Compute metrics ---\n",
    "        # Get span indexes\n",
    "        pred_span_start_idxs, pred_span_end_idxs = SpanExtractor.extract_most_probable(pred_answer_start_scores, pred_answer_end_scores)\n",
    "        gt_start_idxs = answer_spans_start.cpu().detach()\n",
    "        gt_end_idxs = answer_spans_end.cpu().detach()\n",
    "        # two accs\n",
    "        start_accuracy = torch.sum(gt_start_idxs == pred_span_start_idxs) / len(pred_span_start_idxs)\n",
    "        end_accuracy = torch.sum(gt_end_idxs == pred_span_end_idxs) / len(pred_span_end_idxs)\n",
    "        # Gather stats\n",
    "        acc_loss += loss.item()\n",
    "        acc_start_accuracy += start_accuracy.item()\n",
    "        acc_end_accuracy += end_accuracy.item()\n",
    "        count += 1\n",
    "    time_end = timer()\n",
    "    return {\n",
    "        \"loss\": acc_loss / count, \n",
    "        \"accuracy_start\": acc_start_accuracy / count, \n",
    "        \"accuracy_end\": acc_end_accuracy / count,\n",
    "        \"time\": time_end - time_start\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def validation_step(model, scaler, loss_function, dataloader, device=\"cpu\", show_progress=False):\n",
    "    acc_loss = 0\n",
    "    acc_start_accuracy = 0\n",
    "    acc_end_accuracy = 0\n",
    "    count = 0\n",
    "\n",
    "    time_start = timer()\n",
    "    wrapped_dataloader = tqdm(dataloader) if show_progress else dataloader\n",
    "    \n",
    "    model.eval()\n",
    "    for batch in wrapped_dataloader:\n",
    "        answer_spans_start = batch[\"y_gt\"][:, 0]\n",
    "        answer_spans_end = batch[\"y_gt\"][:, 1]\n",
    "        # Place to right device\n",
    "        answer_spans_start = answer_spans_start.to(device)\n",
    "        answer_spans_end = answer_spans_end.to(device)\n",
    "        # Use Automatic Mixed Precision if enabled\n",
    "        with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):\n",
    "            # Run forward pass\n",
    "            pred_answer_start_scores, pred_answer_end_scores = model(batch)\n",
    "            # Compute the CrossEntropyLoss\n",
    "            loss = (loss_function(pred_answer_start_scores, answer_spans_start) + loss_function(pred_answer_end_scores, answer_spans_end))/2.0\n",
    "        # --- Compute metrics ---\n",
    "        # Get span indexes\n",
    "        pred_span_start_idxs, pred_span_end_idxs = SpanExtractor.extract_most_probable(pred_answer_start_scores, pred_answer_end_scores)\n",
    "        gt_start_idxs = answer_spans_start.cpu().detach()\n",
    "        gt_end_idxs = answer_spans_end.cpu().detach()\n",
    "        # two accs\n",
    "        start_accuracy = torch.sum(gt_start_idxs == pred_span_start_idxs) / len(pred_span_start_idxs)\n",
    "        end_accuracy = torch.sum(gt_end_idxs == pred_span_end_idxs) / len(pred_span_end_idxs)\n",
    "        # Gather stats\n",
    "        acc_loss += loss.item()\n",
    "        acc_start_accuracy += start_accuracy.item()\n",
    "        acc_end_accuracy += end_accuracy.item()\n",
    "        count += 1\n",
    "    time_end = timer()\n",
    "    return {\n",
    "        \"loss\": acc_loss / count, \n",
    "        \"accuracy_start\": acc_start_accuracy / count, \n",
    "        \"accuracy_end\": acc_end_accuracy / count,\n",
    "        \"time\": time_end - time_start\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_params_for_optimizer(model, no_decay, weight_decay=0.0001):\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    optimizer_parameters = [\n",
    "        {\n",
    "            'params': [\n",
    "                p for n, p in param_optimizer if not any(\n",
    "                    nd in n for nd in no_decay\n",
    "                )\n",
    "            ], \n",
    "            'weight_decay': weight_decay\n",
    "        },\n",
    "        {\n",
    "            'params': [\n",
    "                p for n, p in param_optimizer if any(\n",
    "                    nd in n for nd in no_decay\n",
    "                )\n",
    "            ],\n",
    "            'weight_decay': 0.0\n",
    "        },\n",
    "    ]\n",
    "    return optimizer_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define baseline model\n",
    "model = params_dict[\"span_model\"](768, 2, params_dict, dropout_rate=params_dict[\"train_params\"][\"dropout_rate\"]).to(device)\n",
    "\n",
    "# Define parameters on which to apply L2 decay\n",
    "no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "if params_dict[\"train_params\"][\"weight_decay\"] > 0.0:\n",
    "    model_params_optimizer = get_params_for_optimizer(model, no_decay, weight_decay=params_dict[\"train_params\"][\"weight_decay\"])\n",
    "else:\n",
    "    model_params_optimizer = model.parameters()\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = AdamW(\n",
    "    model_params_optimizer, \n",
    "    lr=params_dict[\"train_params\"][\"initial_lr\"], \n",
    "    correct_bias=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate the number of train steps for LR scheduler\n",
    "num_train_steps = int(\n",
    "    (len(df_train) / params_dict[\"train_params\"][\"batch_size_train\"]) * params_dict[\"train_params\"][\"epochs\"]\n",
    ")\n",
    "\n",
    "num_warmup_steps = int(num_train_steps * 0.1) # 10% of warmup steps\n",
    "\n",
    "# LR scheduler\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=num_warmup_steps,\n",
    "    num_training_steps=num_train_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=use_amp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_QA = CustomQADatasetBERT(tokenizer_fn_train, df_train, paragraphs_mapper)\n",
    "dataset_val_QA = CustomQADatasetBERT(tokenizer_fn_train, df_val, paragraphs_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader = torch.utils.data.DataLoader(\n",
    "    dataset_train_QA, collate_fn = bert_padder_collate_fn, \n",
    "    batch_size=params_dict[\"train_params\"][\"batch_size_train\"], shuffle=True\n",
    ")\n",
    "val_data_loader = torch.utils.data.DataLoader(\n",
    "    dataset_val_QA, collate_fn = bert_padder_collate_fn, \n",
    "    batch_size=params_dict[\"train_params\"][\"batch_size_val\"], shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = {\n",
    "    \"train_loss\": [], \"train_acc_start\": [], \"train_acc_end\": [],\n",
    "    \"val_loss\": [], \"val_acc_start\": [], \"val_acc_end\": []\n",
    "}\n",
    "loop_start = timer()\n",
    "for epoch in range(params_dict[\"train_params\"][\"epochs\"]):\n",
    "    train_dict = train_step(model, scaler, optimizer, loss_function, train_data_loader,scheduler=scheduler, device=device, show_progress=True)\n",
    "    val_dict = validation_step(model, scaler, loss_function, val_data_loader, device=device, show_progress=True)\n",
    "    cur_lr = optimizer.param_groups[0]['lr']\n",
    "    print(f'Epoch: {epoch}, '\n",
    "          f'lr: {cur_lr}, '\n",
    "          f'Train loss: {train_dict[\"loss\"]:.4f}, '\n",
    "          f'Train acc start: {train_dict[\"accuracy_start\"]:.4f}, '\n",
    "          f'Train acc end: {train_dict[\"accuracy_end\"]:.4f}, '\n",
    "          f'Val loss: {val_dict[\"loss\"]:.4f}, '\n",
    "          f'Val acc start: {val_dict[\"accuracy_start\"]:.4f}, '\n",
    "          f'Val acc end: {val_dict[\"accuracy_end\"]:.4f}, '\n",
    "          f'Time: {train_dict[\"time\"]:.4f}')\n",
    "    history[\"train_loss\"].append(train_dict[\"loss\"]);history[\"train_acc_start\"].append(train_dict[\"accuracy_start\"]);history[\"train_acc_end\"].append(train_dict[\"accuracy_end\"]);\n",
    "    history[\"val_loss\"].append(val_dict[\"loss\"]);history[\"val_acc_start\"].append(val_dict[\"accuracy_start\"]);history[\"val_acc_end\"].append(val_dict[\"accuracy_end\"]);\n",
    "loop_end = timer()\n",
    "print(f\"Elapsed time: {(loop_end - loop_start):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment below line to save model to disk\n",
    "torch.save(model.state_dict(), \"distilroberta_extralinear_google_2_epochs.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment below line to load model from disk\n",
    "#model.load_state_dict(torch.load(\"distilbert_mdl.pt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantitative evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_paragraphs_mapper, test_df = build_mappers_and_dataframe_bert(tokenizer, tokenizer_fn_preprocess, test_data, limit_answers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test_QA = CustomQADatasetBERT(tokenizer_fn_train, test_df, test_paragraphs_mapper)\n",
    "test_data_loader = torch.utils.data.DataLoader(\n",
    "    dataset_test_QA, collate_fn = bert_padder_collate_fn, \n",
    "    batch_size=params_dict[\"train_params\"][\"batch_size_test\"], shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1349/1349 [00:53<00:00, 25.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"exact\": 69.29990539262063,\n",
      "  \"f1\": 79.02643710797072,\n",
      "  \"total\": 10570,\n",
      "  \"HasAns_exact\": 69.29990539262063,\n",
      "  \"HasAns_f1\": 79.02643710797072,\n",
      "  \"HasAns_total\": 10570\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "with open(test_file_json, \"r\") as f:\n",
    "    dataset_json = json.load(f)\n",
    "pred_dict = build_evaluation_dict_bert(model, scaler, test_data_loader, test_paragraphs_mapper, tokenizer, device, show_progress=True)\n",
    "eval_results = evaluate_predictions(dataset_json, pred_dict)\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple qualitative evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer_span_helper(context, question, model, tokenizer_fn, tokenizer, device=\"cpu\"):\n",
    "    tokenized_input = tokenizer_fn(question, context)\n",
    "    output_span = model({\n",
    "        \"input_ids\": torch.tensor(tokenized_input[\"input_ids\"]).to(device), \n",
    "        \"attention_mask\": torch.tensor(tokenized_input[\"attention_mask\"]).to(device)\n",
    "    })\n",
    "    start, end = SpanExtractor.extract_most_probable(output_span[0], output_span[1])\n",
    "    start = start.item()\n",
    "    end = end.item()\n",
    "    return tokenizer.decode(tokenized_input[\"input_ids\"][0][start:end], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"This is a test message, written to see if our model can correctly predict its outputs.\"\n",
    "question = \"Who needs to predict its outputs?\"\n",
    "pred_answer = get_answer_span_helper(context, question, model, tokenizer_fn_train, tokenizer, device=\"cuda\")\n",
    "print(pred_answer)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "NLP_Project.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
